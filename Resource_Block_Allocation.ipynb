{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN07MtdRhkI41uAHFvEQV3r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitHrsh/5G-NR_Resource_Allocation/blob/main/Resource_Block_Allocation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Radio Resource Block Allocation\n",
        "\n"
      ],
      "metadata": {
        "id": "hAUvhAwOjW4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement:\n",
        "Given a 5G NR base station, and 5 UEs moving dynamically within the range of the BS, allocate resource blocks optimally.\n",
        "RBs are allocated according to channel quality. Our goal is to provide fairness and maximize throughput\n",
        "\n",
        "**For Channel State Indicator, SNR is calculated from pathloss and transmission power from base station**\n",
        "\n",
        "###Problem Setup:\n",
        "Allocate a set of available Resource Blocks (RBs) to multiple User Equipments (UEs) to optimize network performance, specifically aiming to maximize data rates and maintain fairness.\n",
        "Dynamic Environment: The environment is dynamic as users move, leading to changing signal strengths and path losses. The challenge is to adapt the allocation of RBs in real-time to reflect these changes.\n",
        "\n",
        "##Approach 1: Allocation using Hopfield Neural Network\n",
        "\n",
        "The RBs are allocated to UEs at the slot boundary\n",
        "based on their channel states. Therefore, we use channel aware based\n",
        "Generalized Proportional Fair (GPF) scheduling. GPF based formulation gives different\n",
        "levels of the trade-off between total data rate and fairness by using\n",
        "different values of the GPF parameter 𝛼. The data rate and user\n",
        "fairness trade-off optimization problem has to maximize the total\n",
        "data rate of all UEs while maintaining a certain level of long-term\n",
        "fairness\n",
        "\n",
        "We use an HNN, which is a type of non-training neural network, to achieve this. We set weights explicitly using CSI, and update the neurons till the Energy function achieves a global minimum. The weights are set in such a way to allow for GPF and maximized learning rates.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y0X1fmQvD7Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "num_ues = 5\n",
        "transmission_power_dbm = 46  # Transmission power in dBm\n",
        "noise_power_dbm = -90  # Noise power in dBm\n",
        "frequency_mhz = 2000  # Frequency in MHz\n",
        "base_station_coords = (0, 0)\n",
        "area_size = 1000\n",
        "alpha = 0.5\n",
        "num_rbs = 200\n",
        "iterations = 150\n",
        "\n",
        "# Generate random coordinates for UEs\n",
        "np.random.seed(0)\n",
        "ue_coords = np.random.uniform(0, area_size, (num_ues, 2))\n",
        "\n",
        "# Function to update UE positions\n",
        "def update_ue_positions(ue_coords, timeslot):\n",
        "    step_size = 1.0\n",
        "    ue_coords[0, 0] += step_size  # UE1 moving away\n",
        "    ue_coords[0, 1] += step_size\n",
        "    ue_coords[1, 0] -= step_size  # UE2 moving towards\n",
        "    ue_coords[1, 1] -= step_size\n",
        "    return ue_coords\n",
        "\n",
        "# Cost Hata Model Parameters\n",
        "def cost_hata_path_loss(d_km, frequency_mhz, base_height_m, ue_height_m, urban_area=True):\n",
        "    A = 69.55 + 26.16 * np.log10(frequency_mhz) - 13.82 * np.log10(base_height_m)\n",
        "    B = 44.9 - 6.55 * np.log10(base_height_m)\n",
        "    C = (1.1 * np.log10(frequency_mhz) - 0.7) * ue_height_m - (1.56 * np.log10(frequency_mhz) - 0.8)\n",
        "    if urban_area:\n",
        "        path_loss = A + B * np.log10(d_km/1000) - C\n",
        "    else:\n",
        "        path_loss = A + B * np.log10(d_km/1000) - C\n",
        "    return path_loss\n",
        "\n",
        "# Convert transmission power and noise power to linear scale\n",
        "transmission_power = 10 ** ((transmission_power_dbm - 30) / 10)  # in Watts\n",
        "noise_power = 10 ** ((noise_power_dbm - 30) / 10)  # in Watts\n",
        "\n",
        "#parameters\n",
        "theta = np.zeros((num_ues, num_rbs))\n",
        "neuron_states = np.random.choice([0, 1], size=(num_ues, num_rbs))\n",
        "rb_bandwidth = 180e3  # 180 kHz\n",
        "total_bandwidth = num_rbs * rb_bandwidth\n",
        "avg_data_rates = np.ones(num_ues)  # Start with equal average data rates\n",
        "\n",
        "# update average data rates\n",
        "def update_avg_data_rates(allocation, channel_gains, transmission_power, noise_power, rb_bandwidth, avg_data_rates, decay=0.8):\n",
        "    for u in range(num_ues):\n",
        "        data_rate = 0\n",
        "        for rb in allocation[u]:\n",
        "            data_rate += rb_bandwidth * np.log2(1 + (transmission_power * channel_gains[u]) / (noise_power*total_bandwidth))\n",
        "        avg_data_rates[u] = decay * avg_data_rates[u] + (1 - decay) * data_rate\n",
        "    return avg_data_rates\n",
        "\n",
        "# calculate weights\n",
        "def calculate_weights(channel_gains, transmission_power, noise_power, rb_bandwidth, alpha, avg_data_rates):\n",
        "    weights = np.zeros((num_ues, num_rbs, num_ues, num_rbs))\n",
        "    for u in range(num_ues):\n",
        "        for b in range(num_rbs):\n",
        "            for u_prime in range(num_ues):\n",
        "                for b_prime in range(num_rbs):\n",
        "                    if u == u_prime and b == b_prime:\n",
        "                        weights[u, b, u_prime, b_prime] = ((rb_bandwidth) * np.log2(\n",
        "                            1 + (transmission_power * channel_gains[u]) / (noise_power*total_bandwidth)\n",
        "                        ) )/ (avg_data_rates[u] ** alpha)\n",
        "                    else:\n",
        "                        weights[u, b, u_prime, b_prime] = 0\n",
        "    return weights\n",
        "\n",
        "def update_neurons(neuron_states, weights, theta):\n",
        "    new_states = np.copy(neuron_states)\n",
        "    num_ues, num_rbs = neuron_states.shape\n",
        "\n",
        "    for b in range(num_rbs):\n",
        "        max_value = -np.inf\n",
        "        selected_ue = -1\n",
        "\n",
        "        for u in range(num_ues):\n",
        "            weighted_sum = np.sum(weights[u, b, :, :] * neuron_states)\n",
        "\n",
        "            if weighted_sum >= theta[u, b] and weighted_sum > max_value:\n",
        "                max_value = weighted_sum\n",
        "                selected_ue = u\n",
        "\n",
        "        new_states[:, b] = 0\n",
        "        if selected_ue != -1:\n",
        "            new_states[selected_ue, b] = 1\n",
        "\n",
        "    return new_states\n",
        "\n",
        "# allocation\n",
        "def interpret_allocation(final_states):\n",
        "    allocation = {}\n",
        "    for u in range(num_ues):\n",
        "        allocation[u] = np.where(final_states[u] == 1)[0]  # Find RBs allocated to this UE\n",
        "    return allocation\n",
        "\n",
        "# evaluate allocation (data rates)\n",
        "def evaluate_allocation(allocation, channel_gains, transmission_power, noise_power, rb_bandwidth):\n",
        "    total_data_rate = 0\n",
        "    UE_data_rate = []\n",
        "    for u in range(num_ues):\n",
        "        data_rate = 0\n",
        "        for rb in allocation[u]:\n",
        "            data_rate += rb_bandwidth * np.log2(1 + (transmission_power * channel_gains[u]) / noise_power)\n",
        "        UE_data_rate.append(data_rate)\n",
        "        total_data_rate += data_rate\n",
        "    return UE_data_rate, total_data_rate\n",
        "\n",
        "# Jain's Fairness Index\n",
        "def calculate_fairness(allocation, channel_gains, transmission_power, noise_power, rb_bandwidth):\n",
        "    data_rates = []\n",
        "    for u in range(num_ues):\n",
        "        data_rate = 0\n",
        "        for rb in allocation[u]:\n",
        "            data_rate += rb_bandwidth * np.log2(1 + (transmission_power * channel_gains[u]) / noise_power)\n",
        "        data_rates.append(data_rate)\n",
        "\n",
        "    data_rates = np.array(data_rates)\n",
        "    fairness_index = (np.sum(data_rates) ** 2) / (num_ues * np.sum(data_rates ** 2))\n",
        "    return fairness_index\n",
        "\n",
        "def compute_energy(neuron_states, weights):\n",
        "    energy = 0\n",
        "    num_ues, num_rbs = neuron_states.shape\n",
        "    for b in range(num_rbs):\n",
        "        for u in range(num_ues):\n",
        "            weighted_sum = np.sum(weights[u, b, :, :] * neuron_states)\n",
        "            energy -= weighted_sum  # Assuming energy function to be minimized\n",
        "    return energy\n",
        "\n",
        "# Run the network until convergence and track data\n",
        "def run_hopfield(neuron_states, weights, theta, avg_data_rates, iterations):\n",
        "    data_rate_history = []\n",
        "    fairness_history = []\n",
        "    energy_history = []\n",
        "\n",
        "    for i in range(iterations):\n",
        "        # Update UE positions for this iteration\n",
        "        ue_coords_updated = update_ue_positions(ue_coords, i)\n",
        "\n",
        "        # Recalculate distances and path losses\n",
        "        distances = np.linalg.norm(ue_coords_updated - np.array(base_station_coords), axis=1)\n",
        "        path_losses = np.array([cost_hata_path_loss(d / 1000, frequency_mhz, base_height_m=30, ue_height_m=1.5) for d in distances])\n",
        "        snr_db = transmission_power_dbm - path_losses - noise_power_dbm\n",
        "        snr_linear = 10 ** (snr_db / 10)\n",
        "        channel_gains = np.sqrt(snr_linear)\n",
        "\n",
        "        # Update weights based on new channel gains\n",
        "        weights = calculate_weights(channel_gains, transmission_power, noise_power, rb_bandwidth, alpha, avg_data_rates)\n",
        "        neuron_states = update_neurons(neuron_states, weights, theta)\n",
        "        allocation = interpret_allocation(neuron_states)\n",
        "\n",
        "        # Update average data rates\n",
        "        avg_data_rates = update_avg_data_rates(allocation, channel_gains, transmission_power, noise_power, rb_bandwidth, avg_data_rates)\n",
        "\n",
        "        UE_data_rate, _ = evaluate_allocation(allocation, channel_gains, transmission_power, noise_power, rb_bandwidth)\n",
        "        data_rate_history.append(UE_data_rate)\n",
        "\n",
        "        fairness = calculate_fairness(allocation, channel_gains, transmission_power, noise_power, rb_bandwidth)\n",
        "        fairness_history.append(fairness)\n",
        "\n",
        "        energy = compute_energy(neuron_states, weights)\n",
        "        energy_history.append(energy)\n",
        "\n",
        "        #print(f\"Iteration {i+1}: Allocation: {allocation}\")\n",
        "        #print(f\"UE Data Rates: {UE_data_rate}\")\n",
        "        #print(f\"Fairness Index: {fairness}\")\n",
        "        #print(f\"Energy: {energy}\")\n",
        "\n",
        "    return neuron_states, data_rate_history, fairness_history\n",
        "\n",
        "# Calculate initial weights\n",
        "distances = np.linalg.norm(ue_coords - np.array(base_station_coords), axis=1)\n",
        "path_losses = np.array([cost_hata_path_loss(d / 1000, frequency_mhz, base_height_m=30, ue_height_m=1.5) for d in distances])\n",
        "snr_db = transmission_power_dbm - path_losses - noise_power_dbm\n",
        "snr_linear = 10 ** (snr_db / 10)\n",
        "channel_gains = np.sqrt(snr_linear)\n",
        "\n",
        "weights = calculate_weights(channel_gains, transmission_power, noise_power, rb_bandwidth, alpha, avg_data_rates)\n",
        "\n",
        "# Run Hopfield\n",
        "final_states, data_rate_history, fairness_history = run_hopfield(neuron_states, weights, theta, avg_data_rates, iterations)\n",
        "\n",
        "# Final allocation and data rates\n",
        "allocation = interpret_allocation(final_states)\n",
        "UE_data_rate, total_data_rate = evaluate_allocation(allocation, channel_gains, transmission_power, noise_power, rb_bandwidth)\n",
        "print(\"Final RB Allocation:\", allocation)\n",
        "print(\"Final UE Data Rates:\", UE_data_rate)\n",
        "print(\"Total Data Rate:\", total_data_rate)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(base_station_coords[0], base_station_coords[1], color='red', marker='*', s=200, label='Base Station')\n",
        "plt.scatter(ue_coords[:, 0], ue_coords[:, 1], color='blue', marker='o', s=100, label='UEs')\n",
        "\n",
        "for i, (x, y) in enumerate(ue_coords):\n",
        "    plt.text(x + 10, y, f'UE{i+1}', fontsize=12)\n",
        "\n",
        "plt.xlim(-100, 1100)\n",
        "plt.ylim(-100, 1100)\n",
        "plt.title('UEs and Base Station Location')\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "ukjuqwHeljHn",
        "outputId": "7d50701a-7c86-486c-e637-3a22535e6f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final RB Allocation: {0: array([  1,   2,   6,   7,  14,  19,  27,  29,  39,  42,  44,  55,  64,\n",
            "        66,  67,  77,  83,  84, 106, 120, 126, 127, 129, 133, 135, 154,\n",
            "       167, 170, 180, 194, 197]), 1: array([  3,   5,   8,   9,  10,  15,  21,  23,  30,  32,  34,  35,  37,\n",
            "        40,  41,  45,  50,  60,  65,  73,  79,  82,  88,  89,  94,  95,\n",
            "        96,  98, 100, 102, 108, 112, 113, 114, 115, 123, 125, 128, 132,\n",
            "       138, 139, 141, 159, 160, 162, 165, 169, 172, 173, 174, 175, 176,\n",
            "       181, 186, 187, 195, 198]), 2: array([  0,   4,  11,  12,  13,  16,  17,  18,  20,  22,  24,  25,  26,\n",
            "        28,  31,  33,  36,  46,  48,  49,  51,  52,  53,  56,  57,  58,\n",
            "        59,  61,  63,  68,  69,  70,  71,  72,  74,  76,  78,  80,  81,\n",
            "        85,  86,  87,  90,  93,  97,  99, 101, 103, 104, 107, 109, 111,\n",
            "       116, 117, 119, 121, 122, 124, 130, 131, 136, 137, 140, 142, 143,\n",
            "       144, 145, 146, 147, 148, 149, 150, 151, 152, 155, 156, 157, 158,\n",
            "       161, 164, 166, 168, 171, 177, 179, 182, 183, 184, 185, 188, 190,\n",
            "       191, 192, 193, 196, 199]), 3: array([ 38,  43,  47,  54,  91,  92, 105, 110, 118, 134, 163, 189]), 4: array([ 62,  75, 153, 178])}\n",
            "Final UE Data Rates: [352021164.7590655, 649973097.6365383, 1096913759.9999077, 135733726.83305877, 45165639.44918877]\n",
            "Total Data Rate: 2279807388.677759\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAK9CAYAAAAqk9rwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAByEklEQVR4nO3deVxU9f7H8fewg4AoIkiZouKeuZWiuSWK+5ItGuWSadc1tdK85lqm2aKppentqi0uWWZlXhWXstTcl1xSy31BM0VEXFjO74/5MTmCCjrAwHk9H495wHzP95z5nPkivTt8z3cshmEYAgAAAEzCJbcLAAAAAHISARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARiA6f3444+yWCz68ccfc7uUfM1isWjUqFG5XUae0LVrV5UsWTK3ywDyLQIwAEnSqFGjZLFYdO7cuQy3V65cWQ0bNrQ9P3LkiCwWyy0f48ePz6HKc87s2bPTnWfRokXVqFEj/e9//8vt8m7r+++/V4MGDVS0aFH5+PioVKlSeuqpp7Rs2TJbn1OnTmnUqFHasWPHXb/O0qVLnS7k3ulnO7c44v0GcHfccrsAAHlbp06d1KJFi3Tt1apVy4VqcsaYMWMUFhYmwzB05swZzZ49Wy1atND333+vVq1a5XZ56bz77rt69dVX1aBBAw0dOlQ+Pj76448/tHLlSs2fP1/NmjWTZA1ko0ePVsmSJVW1atW7eq2lS5fqww8/zDAEX7lyRW5u/Gcnze3e75kzZyo1NTV3CgNMgN9EAO5J9erV9eyzz+Z2GTmqefPmqlmzpu159+7dFRwcrHnz5jldAE5OTtYbb7yhJk2aaMWKFem2nz17Nsdq8fLyyrHXyuvc3d1zuwQgX2MKBIBst2XLFkVFRalIkSLy9vZWWFiYnn/++Tvu9+2336ply5YKDQ2Vp6enSpcurTfeeEMpKSl2/Ro2bKjKlStr7969atSokXx8fHTfffdpwoQJ6Y554sQJtWvXTgUKFFDRokU1cOBAXbt27Z7OLyAgQN7e3umubr777ruqU6eOAgMD5e3trRo1auirr75Kt39MTIweffRRBQQEyNfXV+XKldO///1vuz7Xrl3TyJEjVaZMGXl6eqp48eIaPHjwHWs/d+6c4uPjVbdu3Qy3Fy1aVJJ1HvTDDz8sSerWrZttisfs2bMlST///LOefPJJPfDAA7bXHzhwoK5cuWI7VteuXfXhhx9Kkt00kTQZzQHevn27mjdvLn9/f/n6+qpx48b69ddf7fqkTT1Zt26dBg0apKCgIBUoUEDt27fXX3/9ddvzz4rVq1erXr16KlCggAICAtS2bVvt27cvXb+TJ0+qe/futp/LsLAw9erVS9evX5cknT9/Xq+88ooefPBB+fr6yt/fX82bN9fOnTttx7jT+53RHODLly/r5ZdfVvHixeXp6aly5crp3XfflWEYdv0sFov69u2rxYsXq3LlyvL09FSlSpXsprsAZscVYAD3JDExMcO5lQEBAXJzc9PZs2fVtGlTBQUF6bXXXlNAQICOHDmiRYsW3fHYs2fPlq+vrwYNGiRfX1+tXr1aI0aMUHx8vN555x27vhcuXFCzZs30+OOP66mnntJXX32lIUOG6MEHH1Tz5s0lWf8E37hxYx07dkz9+/dXaGioPvvsM61evTpL53zx4kWdO3dOhmHo7NmzmjJlihISEtJdCf/ggw/Upk0bRUdH6/r165o/f76efPJJLVmyRC1btpQk7dmzR61atVKVKlU0ZswYeXp66o8//tC6detsx0lNTVWbNm30yy+/qGfPnqpQoYJ+++03TZw4UQcOHNDixYtvWWvRokXl7e2t77//Xv369VPhwoUz7FehQgWNGTNGI0aMUM+ePVWvXj1JUp06dSRJCxcuVGJionr16qXAwEBt2rRJU6ZM0YkTJ7Rw4UJJ0osvvqhTp04pJiZGn3322R3fxz179qhevXry9/fX4MGD5e7uro8//lgNGzbUTz/9pFq1atn179evnwoVKqSRI0fqyJEjmjRpkvr27asFCxbc8bXuZOXKlWrevLlKlSqlUaNG6cqVK5oyZYrq1q2rbdu22cLoqVOn9MgjjyguLk49e/ZU+fLldfLkSX311VdKTEyUh4eHDh06pMWLF+vJJ59UWFiYzpw5o48//lgNGjTQ3r17FRoaesf3+2aGYahNmzZas2aNunfvrqpVq2r58uV69dVXdfLkSU2cONGu/y+//KJFixapd+/e8vPz0+TJk9WhQwcdO3ZMgYGB9/x+AXmeAQCGYYwcOdKQZPz1118Zbq9UqZLRoEED2/PDhw8bkm752LBhg2EYhvHNN98YkozNmzdnuabExMR0bS+++KLh4+NjXL161dbWoEEDQ5Lx6aef2tquXbtmhISEGB06dLC1TZo0yZBkfPnll7a2y5cvG2XKlDEkGWvWrLltPbNmzcrwXD09PY3Zs2ffsf7r168blStXNh577DFb28SJE2/7vhuGYXz22WeGi4uL8fPPP9u1T58+3ZBkrFu37rZ1jxgxwpBkFChQwGjevLkxduxYY+vWren6bd682ZBkzJo1647nYhiGMW7cOMNisRhHjx61tfXp08e41X9aJBkjR460PW/Xrp3h4eFh/Pnnn7a2U6dOGX5+fkb9+vVtbWnve2RkpJGammprHzhwoOHq6mrExcXd9vzv9LNtGIZRtWpVo2jRosbff/9ta9u5c6fh4uJidO7c2dbWuXNnw8XFJcOf57Tarl69aqSkpNhtO3z4sOHp6WmMGTPG1na797tLly5GiRIlbM8XL15sSDLefPNNu35PPPGEYbFYjD/++MPWJsnw8PCwa9u5c6chyZgyZcot3wPATJgCAeCe9OzZUzExMekeFStWlGS9EixJS5YsUVJSUpaO7e3tbfv+0qVLOnfunOrVq6fExET9/vvvdn19fX3trsB6eHjokUce0aFDh2xtS5cuVbFixfTEE0/Y2nx8fNSzZ88s1fXhhx/azvPzzz9Xo0aN9MILL6S7qn1j/RcuXNDFixdVr149bdu2zdae9v58++23t7zpaeHChapQoYLKly+vc+fO2R6PPfaYJGnNmjW3rXf06NGaO3euqlWrpuXLl2vYsGGqUaOGqlevnuGf+DNy47lcvnxZ586dU506dWQYhrZv356pY9woJSVFK1asULt27VSqVClbe7FixfTMM8/ol19+UXx8vN0+PXv2tJtSUa9ePaWkpOjo0aNZfv0bnT59Wjt27FDXrl3trpBXqVJFTZo00dKlSyVZr8QvXrxYrVu3tpsDniatNk9PT7m4uNjO8++//7ZNbblx7LNi6dKlcnV1Vf/+/e3aX375ZRmGkW4VksjISJUuXdruXPz9/e3+PQBmRgAGkGk3ho804eHhioyMTPfw9/eXJDVo0EAdOnTQ6NGjVaRIEbVt21azZs3K1LzbPXv2qH379ipYsKD8/f0VFBRkC7kXL16063v//fenq69QoUK6cOGC7fnRo0dVpkyZdP3KlSuXuTfg/z3yyCO284yOjtYPP/ygihUrqm/fvrZ5oJI19NeuXVteXl4qXLiwgoKCNG3aNLvan376adWtW1cvvPCCgoOD1bFjR3355Zd2YfjgwYPas2ePgoKC7B5ly5aVlLkb2Tp16qSff/5ZFy5c0IoVK/TMM89o+/btat26ta5evXrH/Y8dO2YLiL6+vgoKClKDBg0kpR+LzPjrr7+UmJiY4XtfoUIFpaam6vjx43btDzzwgN3zQoUKSZLdGN+NtAB9q1rOnTuny5cv66+//lJ8fLwqV6582+OlpqZq4sSJCg8Pl6enp4oUKaKgoCDt2rXrrt6rtBpDQ0Pl5+eXrr4bzyHNze+VlP7fA2BmzAEGIOmfO/RvvKnpRomJiXd1F7/FYtFXX32lX3/9Vd9//72WL1+u559/Xu+9955+/fVX+fr6ZrhfXFycGjRoIH9/f40ZM0alS5eWl5eXtm3bpiFDhqS7Wurq6prhcYybbhDKDi4uLmrUqJE++OADHTx4UJUqVdLPP/+sNm3aqH79+vroo49UrFgxubu7a9asWZo7d65tX29vb61du1Zr1qzRDz/8oGXLlmnBggV67LHHtGLFCrm6uio1NVUPPvig3n///Qxfv3jx4pmu1d/fX02aNFGTJk3k7u6uOXPmaOPGjbYwm5GUlBQ1adJE58+f15AhQ1S+fHkVKFBAJ0+eVNeuXXNsua7cHOOseOuttzR8+HA9//zzeuONN1S4cGG5uLhowIABvFeAkyAAA5AklShRQpK0f//+dIEqMTFRx48fV9OmTe/6+LVr11bt2rU1duxYzZ07V9HR0Zo/f75eeOGFDPv/+OOP+vvvv7Vo0SLVr1/f1n748OG7rqFEiRLavXu3DMOwuwq8f//+uz5mmuTkZElSQkKCJOnrr7+Wl5eXli9fLk9PT1u/WbNmpdvXxcVFjRs3VuPGjfX+++/rrbfe0rBhw7RmzRrbn7J37typxo0bZ3gV/m7VrFlTc+bM0enTpyVlfIVfkn777TcdOHBAc+bMUefOnW3tMTEx6fpmtr6goCD5+Phk+N7//vvvcnFxyVKwvxc3/uxnVEuRIkVUoEABeXt7y9/fX7t3777t8b766is1atRIn3zyiV17XFycihQpYnuelbEsUaKEVq5cqUuXLtldBU6bCpR2DgAyhykQACRJjRs3loeHh6ZNm5buKtWMGTOUnJxsW00hKy5cuJDuqlPaov+3mwaRdgXrxn2vX7+ujz76KMs1pGnRooVOnTpltxRZYmKiZsyYcdfHlKSkpCStWLFCHh4etj9Ju7q6ymKx2C3ZduTIkXQrNpw/fz7d8W5+f5566imdPHlSM2fOTNf3ypUrunz58i1rS0xM1IYNGzLcljZvNO1P/wUKFJBkDWo3ymgsDMPQBx98kO6YtzrGzVxdXdW0aVN9++23OnLkiK39zJkzmjt3rh599FHbNJrsVqxYMVWtWlVz5syxq3v37t1asWKF7YNeXFxc1K5dO33//ffasmVLuuOkvT+urq7pfuYXLlyokydP2rVl9r2SrD+7KSkpmjp1ql37xIkTZbFY7urfJmBmXAEGIMm6XNaIESP0+uuvq379+mrTpo18fHy0fv16zZs3T02bNlXr1q3T7bdt2zZ9/vnn6dpLly6tiIgIzZkzRx999JHat2+v0qVL69KlS5o5c6b8/f0z/AS5NHXq1FGhQoXUpUsX9e/fXxaLRZ999tk9/Qm3R48emjp1qjp37qytW7eqWLFi+uyzz+Tj45Ol4/zvf/+zXXk7e/as5s6dq4MHD+q1116zhbaWLVvq/fffV7NmzfTMM8/o7Nmz+vDDD1WmTBnt2rXLdqwxY8Zo7dq1atmypUqUKKGzZ8/qo48+0v33369HH31UkvTcc8/pyy+/1L/+9S+tWbNGdevWVUpKin7//Xd9+eWXWr58eYY3ZUnWAFynTh3Vrl1bzZo1U/HixRUXF6fFixfr559/Vrt27Wyf2le6dGkFBARo+vTp8vPzU4ECBVSrVi2VL19epUuX1iuvvKKTJ0/K399fX3/9dYbzSWvUqCFJ6t+/v6KiouTq6qqOHTtmWNubb75pWwO5d+/ecnNz08cff6xr165luIbzvXr//ffTjbWLi4v+/e9/65133lHz5s0VERGh7t2725ZBK1iwoN3axW+99ZZWrFihBg0a2JakO336tBYuXKhffvlFAQEBatWqlcaMGaNu3bqpTp06+u233/TFF1/Y3ewn3fr9DgsLS1d769at1ahRIw0bNkxHjhzRQw89pBUrVujbb7/VgAED7G54A5AJubL2BACn9fnnnxu1a9c2ChQoYHh6ehrly5c3Ro8ebbfsmGHceRm0Ll26GIZhGNu2bTM6depkPPDAA4anp6dRtGhRo1WrVsaWLVvuWMu6deuM2rVrG97e3kZoaKgxePBgY/ny5emWLGvQoIFRqVKldPvfvJSUYRjG0aNHjTZt2hg+Pj5GkSJFjJdeeslYtmzZXS+D5uXlZVStWtWYNm2a3RJdhmEYn3zyiREeHm57H2fNmmVbkivNqlWrjLZt2xqhoaGGh4eHERoaanTq1Mk4cOCA3bGuX79uvP3220alSpUMT09Po1ChQkaNGjWM0aNHGxcvXrxlzUlJScbMmTONdu3aGSVKlDA8PT0NHx8fo1q1asY777xjXLt2za7/t99+a1SsWNFwc3OzW6Jr7969RmRkpOHr62sUKVLE6NGjh21prRuX8UpOTjb69etnBAUFGRaLxe5cddMyaIZh/fmIiooyfH19DR8fH6NRo0bG+vXrM3zfb156bM2aNZkat7T3PKOHq6urrd/KlSuNunXrGt7e3oa/v7/RunVrY+/evemOd/ToUaNz585GUFCQ4enpaZQqVcro06eP7b28evWq8fLLLxvFihUzvL29jbp16xobNmwwGjRoYLeU4O3e74x+di9dumQMHDjQCA0NNdzd3Y3w8HDjnXfeSfdzJ8no06dPurpLlChh+3cJmJ3FMJgRDwAAAPNgDjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAU+GDMDIhNTVVp06dkp+fn0M/hhQAAACOYRiGLl26pNDQULm43P4aLwE4E06dOpVjn0kPAACAu3f8+HHdf//9t+1DAM4EPz8/SdY3NKc+mz47JSUlacWKFWratKnc3d1zuxzcgLFxboyP82JsnBdj49zy0/jEx8erePHittx2OwTgTEib9uDv759vArCPj4/8/f3z/A97fsPYODfGx3kxNs6LsXFu+XF8MjNdlZvgAAAAYCoEYAAAAJgKARgAAACmwhxgAADgVFJSUpSUlJTbZZhCUlKS3NzcdPXqVaWkpOR2OXfk7u4uV1fXez4OARgAADiNhIQEnThxQoZh5HYppmAYhkJCQnT8+PE88VkHFotF999/v3x9fe/pOARgAADgFFJSUnTixAn5+PgoKCgoTwSyvC41NVUJCQny9fW944dH5DbDMPTXX3/pxIkTCg8Pv6crwQRgAADgFJKSkmQYhoKCguTt7Z3b5ZhCamqqrl+/Li8vL6cPwJIUFBSkI0eOKCkp6Z4CsPOfKQAAMBWHXPk9cEAKCbF+Rb7hqL8KEIABAED+M3eudOaMNG9eblcCJ0QABgAA+c+CBfZfgRsQgAEAQP6yf7/0++/W7/ftYxpEDjly5IgsFot27NiR26XcEQEYAADkL19/LaXdIOXiYn2ejbp27SqLxWJ7BAYGqlmzZtq1a1e2vu6dpKSkaPz48Spfvry8vb1VuHBh1apVS//5z39sfR577DENHTo0y8fu2rWr2rVrZ9dWvHhxnT59WpUrV77X0rMdARgAAOQvCxZIqanW71NTc2QaRLNmzXT69GmdPn1aq1atkpubm1q1apXtr3s7o0eP1sSJE/XGG29o7969WrNmjXr27Km4uLhseT1XV1eFhITIzc35FxkjAAMAgLzl6lVp/Xpp3br0j++/l3btkm78II2dO63tGfVfv956vHvk6empkJAQhYSEqGrVqnrttdd0/Phx/fXXX7Y+Q4YMUdmyZeXj46NSpUpp+PDhdp94t3PnTjVq1Eh+fn7y9/dXjRo1tGXLFtv2X375RfXq1ZO3t7eKFy+u/v376/Lly7es6bvvvlPv3r315JNPKiwsTA899JC6d++uV155RZL1Ku5PP/2k6dOny9XVVRaLRUeOHFFKSoq6d++usLAweXt7q1y5cvrggw9sxx01apTmzJmjb7/91nbV+8cff8xwCsRPP/2kRx55RJ6enipWrJhee+01JScn27Y3bNhQ/fv31+DBg1W4cGGFhIRo1KhR9zIUmeL8ER0AAOBGM2dK/fvferuLyz9XgNOet2lz6/6TJ0v9+jmsvISEBH3++ecqU6aMAgMDbe1+fn6aPXu2QkND9dtvv6lHjx7y8/PT4MGDJUnR0dGqVq2apk2bJldXV+3YsUPu7u6SpD///FPNmjXTm2++qf/+97/666+/1LdvX/Xt21ezZs3KsI6QkBCtXr1avXv3VlBQULrtH3zwgQ4cOKCyZcvqrbfekouLi4KCgpSamqr7779fCxcuVGBgoNavX6+ePXuqWLFieuqpp/TKK69o3759io+Pt7124cKFderUKbvjnzx5Ui1atFDXrl316aef6vfff1ePHj3k5eVlF3LnzJmjQYMGaePGjdqwYYO6du2qunXrqkmTJvc0DrdDAAYAAHlLjx7WG9umTpUsFvurvZJ9+M3oufTPfv36WY93j5YsWWL7eN7Lly+rWLFiWrJkid2HS7z++uu270uWLKlXXnlF8+fPtwXgY8eO6dVXX1X58uUlSeHh4bb+48aNU3R0tAYMGGDbNnnyZDVo0EDTpk2Tl5dXupref/99PfHEEwoJCVGlSpVUp04dtW3bVs2bN5ckFSxYUB4eHvL29lZISIitVldXV40ePdp2nLCwMG3YsEFffvmlnnrqKfn6+srb21vXrl1TSEjILd+Tjz76SMWLF9fUqVNlsVhUvnx5nTp1SkOGDNGIESNsr1elShWNHDnSdl5Tp07VqlWrsjUAMwUCAADkLV5e0pQp0rffSgULSlmdc+rmZt3vu++sV38zCI9Z1ahRI+3YsUM7duzQpk2bFBUVpebNm+vo0aO2PgsWLFDdunUVEhIiX19fvf766zp27Jht+6BBg/TCCy8oMjJS48eP159//mnbtnPnTs2ePVu+vr62R1RUlFJTU3X48OEMa6pYsaJ2796tX3/9Vc8//7zOnj2r1q1b64UXXrjj+Xz44YeqUaOGgoKC5OvrqxkzZtjVmhn79u1TRESE3YdX1K1bVwkJCTpx4oStrUqVKnb7FStWTGfPns3Sa2UVARgAAORNbdpIu3dLERFZ269OHet+rVs7rJQCBQqoTJkyKlOmjB5++GH95z//0eXLlzVz5kxJ0oYNGxQdHa0WLVpoyZIl2r59u4YNG6br16/bjjFq1Cjt2bNHLVu21OrVq1WxYkV98803kqzTKl588UVbyN6xY4d27typgwcPqnTp0resy8XFRQ8//LAGDBigRYsWafbs2frkk09uGZolaf78+XrllVfUvXt3rVixQjt27FC3bt3sanWktGkeaSwWi1IzumrvQEyBAAAAedd990lr1khvvy29/nr66RA3slikN9+Uhgz5Z5m0bGKxWOTi4qIrV65IktavX68SJUpo2LBhtj43Xh1OU7ZsWZUtW1YDBw5Up06dNGvWLLVv317Vq1fX3r17VaZMmXuqq2LFipJku3nO3d1dKSkpdn3WrVunOnXqqHfv3ra2G69GS5KHh0e6/W5WoUIFff311zIMw3YVeN26dfLz89P9999/T+dxr7gCDAAA8jZXVykTf9aXZJ3vmw3h99q1a4qNjVVsbKz27dunfv36KSEhQa3//ypzeHi4jh07pvnz5+vPP//U5MmTbVd3JenKlSvq27evfvzxRx09elTr1q3T5s2bVaFCBUnWFSTWr1+vvn37aseOHTp48KC+/fZb9e3b95Y1PfHEE5o4caI2btyoo0eP6scff1SfPn1UtmxZ2zzjkiVLauvWrTpy5IjOnTun1NRUhYeHa8uWLVq+fLkOHDig4cOHa/PmzXbHLlmypHbt2qX9+/fr3LlzdqtZpOndu7eOHz+ufv366ffff9e3336rkSNHatCgQXZzo3MDARgAAOR9ixc7tl8WLVu2TMWKFVOxYsVUq1Ytbd68WQsXLlTDhg0lSW3atNHAgQPVt29fVa1aVevXr9fw4cNt+7u6uurvv/9W586dVbZsWT311FNq3ry57Wa0KlWq6KefftKBAwdUr149VatWTSNGjFBoaOgta4qKitL333+v1q1bq2zZsurSpYvKly+vFStW2Nbqffnll+Xq6qrKlSsrKChIx44d04svvqjHH39cTz/9tGrVqqW///7b7mqwJPXo0UPlypVTzZo1FRQUpHXr1qV7/fvuu09Lly7Vpk2b9NBDD+lf//qXunfvbnczYG6xGMbt/lYASYqPj1fBggV18eJF+fv753Y59ywpKUlLly5VixYt0s27Qe5ibJwb4+O8GBvnlZWxuXr1qg4fPqywsLAMVzW4rSZNpNWr/1nxwc1NSk7+56tkvfLbqJEUE3MXZ5I/paamKj4+Xv7+/rl+VTYzbvczkpW85vxnCgAAcDvnz1vnAaeFXxcXqUIFackSqVw563NJSkmx9rtwIfdqhVMgAAMAgLztu++s4TZtua1+/aTNm6WWLaUtW/75kAuLxdrvu+9yr1Y4BQIwAADI2xYutH4NCLBe9Z00SfL0tLZ5eVmff/+9dfuN/WFaBGAAAJC37d4tNWwo7dljveqbkVatrP0aNLB+hamxDjAAAMjb9uyRChT4ZwrErYSGWucA//8auDAvAjAAAMjbfH0z39diyVp/5EtMgQAAAICpEIABAABgKkyBAAAA+YphSH//LSUkWGc7BAbeeXowzIUrwAAAIF+Ii5M++EAKD5eCgqSwMOvX8HBre1xcblcIZ0EABgAAed7y5dL990sDB0qHDtlvO3TI2n7//dZ+jtawYUMNGDAgXfvs2bMV8P9rD48aNUoWiyXdo3z58o4vCHfEFAgAAJCnLV9uXf7XMKyPm6W1Xbli7ffDD1JUVM7WKEmVKlXSypUr7drc3IhiuYErwAAAIM+Ki5M6dLCG3NTU2/dNTbX269Ahd6ZDuLm5KSQkxO5RpEgR2/aPPvpI4eHh8vLyUnBwsJ544omcL9IkCMAAACDPmjNHSky8c/hNk5pq7f/pp9lbV1Zt2bJF/fv315gxY7R//34tW7ZM9evXz+2y8i0CMAAAyJMMQ5oy5e72nTw54+kS2em3336Tr6+v3eNf//qXJOnYsWMqUKCAWrVqpRIlSqhatWrq379/zhZoIkw8AQAAedLff0t//pn1/QzDut/589Yl0nJKuXLl9N1339m1+fv7S5KaNGmiEiVKqFSpUmrWrJmaNWum9u3by8fHJ+cKNBGuAAMAgDwpIeHe9r90yTF1+Pv76+LFi+na4+LiVLBgQdtzDw8PlSlTxu5RtGhRSZKfn5+2bdumefPmqVixYhoxYoQeeughxbF2W7YgAAMAgDzJ1/fe9vfzc0wd5cqV07Zt29K1b9u2TWXLls30cdzc3BQZGakJEyZo165dOnLkiFavXu2YImGHKRAAACBPCgyUSpe2rvOblfm8FotUqpRUuLBj6ujVq5emTp2q/v3764UXXpCnp6d++OEHzZs3T99//72tX3JysmJjY2+qxaLg4GAtWbJEhw4dUv369VWoUCEtXbpUqampKleunGOKhB0CMAAAyJMsFqlfP+uHXGRV//6O+3jkUqVKae3atRo2bJgiIyN1/fp1lS9fXgsXLlSzZs1s/fbs2aNixYrZ7evp6amrV68qICBAixYt0qhRo3T16lWFh4dr3rx5qlSpkmOKhB0CMAAAyLO6dJGGDbN+yEVmlkJzcZG8vaXOnR1bx8MPP6wVK1bccvuoUaM0atSoW25/9NFH9eOPPzq2KNwSc4ABAECeFRAgff219Wquyx1SjYuLtd+iRdb9YF65GoDXrl2r1q1bKzQ0VBaLRYsXL7bbbhiGRowYoWLFisnb21uRkZE6ePCgXZ/z588rOjpa/v7+CggIUPfu3ZVw022hu3btUr169eTl5aXixYtrwoQJ2X1qAAAgh0RFWT/e2NvbGnBvntqQ1ubtLS1dKjVtmjt1wnnkagC+fPmyHnroIX344YcZbp8wYYImT56s6dOna+PGjSpQoICioqJ09epVW5/o6Gjt2bNHMTExWrJkidauXauePXvatsfHx6tp06YqUaKEtm7dqnfeeUejRo3SjBkzsv38AABAzoiKkk6ckCZNst7gdqNSpaztJ08SfmGVq3OAmzdvrubNm2e4zTAMTZo0Sa+//rratm0rSfr0008VHBysxYsXq2PHjtq3b5+WLVumzZs3q2bNmpKkKVOmqEWLFnr33XcVGhqqL774QtevX9d///tfeXh4qFKlStqxY4fef/99u6AMAADytoAA681t/fpZP+Ti0iXrUmeFCzvuhjfkD057E9zhw4cVGxuryMhIW1vBggVVq1YtbdiwQR07dtSGDRsUEBBgC7+SFBkZKRcXF23cuFHt27fXhg0bVL9+fXl4eNj6REVF6e2339aFCxdUqFChdK997do1Xbt2zfY8Pj5ekpSUlKSkpKTsON0clXYO+eFc8hvGxrkxPs6LsXFeWRmb5ORkGYahlJQUpWbmjrbbKFTI+pCsS6Tl9Mce5xXG/78xhmHc83ueE1JSUmQYhpKTk9P9TGXl37/TBuC0dfKCg4Pt2oODg23bYmNjbZ+gksbNzU2FCxe26xMWFpbuGGnbMgrA48aN0+jRo9O1r1ixIl99JGFMTExul4BbYGycG+PjvBgb55WZsXFxcVGxYsV08eJF/mcmh11y1MfiZbPExEQlJiZqzZo16QJ7YmJipo/jtAE4Nw0dOlSDBg2yPY+Pj1fx4sXVtGlT22d252VJSUmKiYlRkyZN5O7untvl4AaMjXNjfJwXY+O8sjI2hmHo5MmTunz5svz9/eVyp2UdcM8Mw9Dly5dVoEABWZx8nkhqaqouX76swMBAValSJV29aX+xzwynDcAhISGSpDNnztgtGn3mzBlVrVrV1ufs2bN2+yUnJ+v8+fO2/UNCQnTmzBm7PmnP0/rczNPTU56enuna3d3d89Uv1vx2PvkJY+PcGB/nxdg4r8yOzX333afDhw/r+PHjOVAVDMPQlStX5O3t7fQBWLL+leC+++6zm9qaJiv/9p02AIeFhSkkJESrVq2yBd74+Hht3LhRvXr1kiRFREQoLi5OW7duVY0aNSRJq1evVmpqqmrVqmXrM2zYMCUlJdnemJiYGJUrVy7D6Q8AACD3eHh4KDw8XNevX8/tUkwhKSlJa9euVf369fPE/zx6eHg45C8DuRqAExIS9Mcff9ieHz58WDt27FDhwoX1wAMPaMCAAXrzzTcVHh6usLAwDR8+XKGhoWrXrp0kqUKFCmrWrJl69Oih6dOnKykpSX379lXHjh0VGhoqSXrmmWc0evRode/eXUOGDNHu3bv1wQcfaOLEiblxygAA4A5cXFzk5eWV22WYgqurq5KTk+Xl5ZUnArCj5GoA3rJlixo1amR7njbvtkuXLpo9e7YGDx6sy5cvq2fPnoqLi9Ojjz6qZcuW2f2j+OKLL9S3b181btxYLi4u6tChgyZPnmzbXrBgQa1YsUJ9+vRRjRo1VKRIEY0YMYIl0AAAAEwqVwNww4YNbctvZMRisWjMmDEaM2bMLfsULlxYc+fOve3rVKlSRT///PNd1wkAAID8g9srAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAcAJjRo1ShaLRefOnctwe+XKldWwYUNJ0pEjR2SxWG75GD9+fIbHSEpKUsWKFWWxWPTuu+9m16kAgNNxy+0CAACO0alTJ7Vo0SJde7Vq1TLsP2XKFB07diy7ywIAp0MABoB8onr16nr22Wcz1ffs2bMaM2aMhgwZohEjRmRzZQDgXJgCAQAm9Nprr6lcuXKZDswAkJ9wBRgA8onExMQM5wwHBATIze2fX/ebNm3SnDlz9Msvv8hiseRkiQDgFLgCDAA5zDCkc+ekI0esXw3DMccdOXKkgoKC0j22bNlyw2sb6tevn55++mlFREQ45oUBII/hCjAA5JC4OGnOHGnKFOnPP/9pL11a6tdP6tJFCgi4++P37NlTTz75ZLr2ihUr2r6fPXu2fvvtN3311Vd3/0IAkMcRgAEgByxfLnXoICUmpt926JA0cKA0bJj09ddSVFTmjnnz9IXw8HBFRkbesn98fLyGDh2qV199VcWLF89K+QCQrxCAASCbLV8utWxpneqQ0XSHtLYrV6z9fvhB8vLy+v+2KxkeMzEx0dYns959911dv35dTz/9tI4cOSJJOnHihCTpwoULOnLkiEJDQ+Xh4ZGl4wJAXsMcYADIRnFx1iu/hiGlpt6+b2qqtV+HDlKRIiUkSfv370/XLzExUcePH1eJEiWyVMuxY8d04cIFVapUSWFhYQoLC1O9evUkSW+99ZbCwsK0d+/eLB0TAPIirgADQDaaM8c67SGzN7qlplr7nznTWB4eHpo2bZoee+wxubj8c71ixowZSk5OVvPmzbNUS//+/dWuXTu7trNnz+rFF19U165d1bZtW4WFhWXpmACQFxGAASCbGIb1hre7MWtWUQ0fPkLDh7+u+vXrq02bNvLx8dH69es1b948NW3aVK1bt7bbZ9u2bfr888/THat06dKKiIhQ9erVVb16dbttaVMhKlWqlC4cA0B+RQAGgGzy99/2qz1klmFY9+vVa5jCwkpq6tSpGjNmjJKTkxUWFqbRo0dryJAhdleFJWnevHmaN29euuN16dKFJc8A4AYEYADIJgkJ97b/pUtSdHS0oqOjb9uvZMmSMu5yMeF72RcA8ipuggOAbOLre2/7+/k5pg7kL6NGjZLFYsnwU/8kqXLlymrYsKEk6xQXi8Vyy8f48eNt+23atEm9e/dWjRo15O7uzqcEIl/jCjAAZJPAQOuHXBw6lLVPe7NYpFKlpMKFs682mEunTp3UokWLdO3VqlWzfb906VL95z//UZUqVVSqVCkdOHAgJ0sEchQBGACyicVi/YS3gQOzvm///tb9AUeoXr26nn322dv26dWrl4YMGSJvb2/17duXAIx8jSkQAJCNunSRfHwkl0z+tnVxsfbv3Dl76wJuFhwcLG9v79wuA8gRXAEGgGwUEGD9eOOWLa3h9nYfhuHiYr3qu2iRdT+Yj2FYVw9JSLDOIQ8MdMxfAhITEzOcMxwQECA3N6IAzIcrwACQzaKirB9v7O1tDTM3B5q0Nm9vaelSqWnT3KkTuScuTvrgAyk8XAoKksLCrF/Dw63tcXH3dvyRI0cqKCgo3WPLli2OKB/Ic/jfPgDIAVFR0okT0qefSpMn268PXKqUdc5vly5SwYK5VyNyx/Ll1o+/TkxMv+3QIesc8mHDrH9JiIq6u9fo2bOnnnzyyXTtFStWvLsDAnkcARgAckhAgDXo9usnnT9vXefXz8+62gM3vJnT8uXW6TGGkfFKIWltV65Y+/3wQ+aOe/MSZuHh4YqMjLzHaoH8gykQAJDDLBbr3M6SJR03xxN5T1yc9cqvYdx+brhk3W4Yaf29JElXrlzJsG9iYqK8vLwcXC2QvxCAAQDIBXPmWKc93Cn8pklNtfY/cqSEJGn//v3p+iQmJur48eMqUaKEI0sF8h0CMAAAOcwwpClT7m7fn35qLA8PD02bNk2pN6XnGTNmKDk5Wc2bN3dAlUD+xRxgAABy2N9/298ImVmGIR09WlT//vcIvfXW66pfv77atGkjHx8frV+/XvPmzVPTpk3VunVru/22bdumzz//PN3xSpcurYiICEnS0aNH9dlnn0mSbXWIN998U5JUokQJPffcc1kvGHBSBGAAAHJYQsK97d+jxzBVrFhSU6dO1ZgxY5ScnKywsDCNHj1aQ4YMkctNn7wyb948zZs3L91xunTpYgvAhw8f1vDhw+22pz1v0KABARj5CgEYAIAc5ut7b/v7+UnR0dGKjo6+bb+SJUvKyGh5iQw0bNgw032BvI45wAAA5LDAQKl06ayvAGKxWPcrXDh76gLMggAMAEAOs1is60Hfjf79WToPuFcEYAAAckGXLpKPj+SSyf8Su7hY+3funL11AWZAAAYAIBcEBFg/3thiuXMIdnGx9lu0yLofgHtDAAYAIJdERVk/3tjb2xpwb57akNbm7S0tXSo1bZo7dQL5DQEYAIBcFBUlnTghTZoklSplv61UKWv7yZOEX8CRWAYNAIBcFhBgvbmtXz/p/Hnp0iXrUmeFC3PDG5AdCMAAADgJi8W6RFpgYG5XAuRvTIEAAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACm4tQBOCUlRcOHD1dYWJi8vb1VunRpvfHGGzIMw9bHMAyNGDFCxYoVk7e3tyIjI3Xw4EG745w/f17R0dHy9/dXQECAunfvroSEhJw+HQAAADgBpw7Ab7/9tqZNm6apU6dq3759evvttzVhwgRNmTLF1mfChAmaPHmypk+fro0bN6pAgQKKiorS1atXbX2io6O1Z88excTEaMmSJVq7dq169uyZG6cEAACAXOaW2wXczvr169W2bVu1bNlSklSyZEnNmzdPmzZtkmS9+jtp0iS9/vrratu2rSTp008/VXBwsBYvXqyOHTtq3759WrZsmTZv3qyaNWtKkqZMmaIWLVro3XffVWhoaO6cHAAAAHKFUwfgOnXqaMaMGTpw4IDKli2rnTt36pdfftH7778vSTp8+LBiY2MVGRlp26dgwYKqVauWNmzYoI4dO2rDhg0KCAiwhV9JioyMlIuLizZu3Kj27dune91r167p2rVrtufx8fGSpKSkJCUlJWXX6eaYtHPID+eS3zA2zo3xcV6MjfNibJxbfhqfrJyDUwfg1157TfHx8SpfvrxcXV2VkpKisWPHKjo6WpIUGxsrSQoODrbbLzg42LYtNjZWRYsWtdvu5uamwoUL2/rcbNy4cRo9enS69hUrVsjHx+eez8tZxMTE5HYJuAXGxrkxPs6LsXFejI1zyw/jk5iYmOm+Th2Av/zyS33xxReaO3euKlWqpB07dmjAgAEKDQ1Vly5dsu11hw4dqkGDBtmex8fHq3jx4mratKn8/f2z7XVzSlJSkmJiYtSkSRO5u7vndjm4AWPj3Bgf58XYOC/Gxrnlp/FJ+4t9Zjh1AH711Vf12muvqWPHjpKkBx98UEePHtW4cePUpUsXhYSESJLOnDmjYsWK2fY7c+aMqlatKkkKCQnR2bNn7Y6bnJys8+fP2/a/maenpzw9PdO1u7u75/kfjhvlt/PJTxgb58b4OC/GxnkxNs4tP4xPVup36lUgEhMT5eJiX6Krq6tSU1MlSWFhYQoJCdGqVats2+Pj47Vx40ZFRERIkiIiIhQXF6etW7fa+qxevVqpqamqVatWDpwFAAAAnIlTXwFu3bq1xo4dqwceeECVKlXS9u3b9f777+v555+XJFksFg0YMEBvvvmmwsPDFRYWpuHDhys0NFTt2rWTJFWoUEHNmjVTjx49NH36dCUlJalv377q2LEjK0AAAACYkFMH4ClTpmj48OHq3bu3zp49q9DQUL344osaMWKErc/gwYN1+fJl9ezZU3FxcXr00Ue1bNkyeXl52fp88cUX6tu3rxo3biwXFxd16NBBkydPzo1TAgAAQC5z6gDs5+enSZMmadKkSbfsY7FYNGbMGI0ZM+aWfQoXLqy5c+dmQ4UAAADIa5x6DjAAAADgaARgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAaAXDJq1ChZLBadO3cuw+2VK1dWw4YNJUlHjhyRxWK55WP8+PG2/WbOnKkGDRooODhYnp6eCgsLU7du3XTkyJEcOCsAcH5uuV0AACDzOnXqpBYtWqRrr1atmu377du3KywsTG3atFGhQoV0+PBhzZw5U0uWLNHOnTsVGhqakyUDgNMhAANAHlK9enU9++yzt+3z0UcfpWtr166datasqU8//VSvvfZadpUHAHkCUyAAwARKliwpSYqLi8vVOgDAGXAFGADykMTExAznDAcEBMjNzf5X+t9//62UlBQdO3ZMY8aMkSQ1btw4R+oEAGdGAAaAbGAY0t9/SwkJkq+vFBgoWSz3ftyRI0dq5MiR6do3bNig2rVr27Xdd999unbtmiQpMDBQkydPVpMmTe69CADI4wjAAOBAcXHSnDnSlCnSn3/+0166tNSvn9SlixQQcPfH79mzp5588sl07RUrVkzX9r///U9Xr17Vvn379Pnnn+vy5ct3/8IAkI8QgAHAQZYvlzp0kBIT0287dEgaOFAaNkz6+mspKipzx7TcdNk4PDxckZGRmdq3UaNGkqTmzZurbdu2qly5snx9fdW3b9/MvTgA5FPcBAcADrB8udSypXTlinX6g2HYb09ru3LF2m/5csnLy0uSdOXKlQyPmZiYaOtzr0qXLq1q1arpiy++cMjxACAvIwADwD2Ki7Ne+TUMKTX19n1TU639OnSQihQpIUnav39/un6JiYk6fvy4SpQo4bA6r1y5oosXLzrseACQVxGAAeAezZljnfZwp/CbJjXV2v/Mmcby8PDQtGnTlHrTzjNmzFBycrKaN2+epVqSk5N14cKFdO2bNm3Sb7/9ppo1a2bpeACQHzEHGADugWFYb3i7G7NmFdXw4SM0fPjrql+/vtq0aSMfHx+tX79e8+bNU9OmTdW6dWu7fbZt26bPP/883bFKly6tiIgIJSQkqHjx4nr66adVqVIlFShQQL/99ptmzZqlggULavjw4XdXLADkIwRgALgHf/9tv9pDZhmGdb9evYYpLKykpk6dqjFjxig5OVlhYWEaPXq0hgwZIhcX+z/UzZs3T/PmzUt3vC5duigiIkI+Pj564YUXtGbNGn311Ve6cuWKQkND1alTJ73++uu2D8QAADMjAAPAPUhIuLf9L12SoqOjFR0dfdt+JUuWlHHznXUZ8PDw0KRJk+6tKADI55gDDAD3wNf33vb383NMHQCAzCMAA8A9CAy0fshFVj/lzWKx7le4cPbUBQC4NQIwANwDi8X6CW93o39/x3w8MgAgawjAAHCPunSRfHwkl0z+RnVxsfbv3Dl76wIAZIwADAD3KCDA+vHGFsudQ7CLi7XfokXW/QAAOY8ADAAOEBUl/fCD5O1tDbg3T21Ia/P2lpYulZo2zZ06AQAEYABwmKgo6cQJadIkqVQp+22lSlnbT54k/AJAbmMdYABwoIAA681t/fpJ589b1/n187Ou9sANbwDgHAjAAJANLBbrEmmBgbldCQDgZkyBAAAAgKkQgAEAAGAqBGAAAACYCgEYAAAApkIABgAAgKkQgAEAAGAqBGAAAACYCgEYAAAApkIABgAAgKk4fQA+efKknn32WQUGBsrb21sPPvigtmzZYttuGIZGjBihYsWKydvbW5GRkTp48KDdMc6fP6/o6Gj5+/srICBA3bt3V0JCQk6fCgAAAJyAUwfgCxcuqG7dunJ3d9f//vc/7d27V++9954KFSpk6zNhwgRNnjxZ06dP18aNG1WgQAFFRUXp6tWrtj7R0dHas2ePYmJitGTJEq1du1Y9e/bMjVMCAABALnPL7QJu5+2331bx4sU1a9YsW1tYWJjte8MwNGnSJL3++utq27atJOnTTz9VcHCwFi9erI4dO2rfvn1atmyZNm/erJo1a0qSpkyZohYtWujdd99VaGhozp4UAAAAcpVTB+DvvvtOUVFRevLJJ/XTTz/pvvvuU+/evdWjRw9J0uHDhxUbG6vIyEjbPgULFlStWrW0YcMGdezYURs2bFBAQIAt/EpSZGSkXFxctHHjRrVv3z7d6167dk3Xrl2zPY+Pj5ckJSUlKSkpKbtON8eknUN+OJf8hrFxboyP82JsnBdj49zy0/hk5RycOgAfOnRI06ZN06BBg/Tvf/9bmzdvVv/+/eXh4aEuXbooNjZWkhQcHGy3X3BwsG1bbGysihYtarfdzc1NhQsXtvW52bhx4zR69Oh07StWrJCPj48jTs0pxMTE5HYJuAXGxrkxPs6LsXFejI1zyw/jk5iYmOm+Th2AU1NTVbNmTb311luSpGrVqmn37t2aPn26unTpkm2vO3ToUA0aNMj2PD4+XsWLF1fTpk3l7++fba+bU5KSkhQTE6MmTZrI3d09t8vBDRgb58b4OC/GxnkxNs4tP41P2l/sM8OpA3CxYsVUsWJFu7YKFSro66+/liSFhIRIks6cOaNixYrZ+pw5c0ZVq1a19Tl79qzdMZKTk3X+/Hnb/jfz9PSUp6dnunZ3d/c8/8Nxo/x2PvkJY+PcGB/nxdg4L8bGueWH8clK/U69CkTdunW1f/9+u7YDBw6oRIkSkqw3xIWEhGjVqlW27fHx8dq4caMiIiIkSREREYqLi9PWrVttfVavXq3U1FTVqlUrB84CAAAAzsSprwAPHDhQderU0VtvvaWnnnpKmzZt0owZMzRjxgxJksVi0YABA/Tmm28qPDxcYWFhGj58uEJDQ9WuXTtJ1ivGzZo1U48ePTR9+nQlJSWpb9++6tixIytAAAAAmJBTB+CHH35Y33zzjYYOHaoxY8YoLCxMkyZNUnR0tK3P4MGDdfnyZfXs2VNxcXF69NFHtWzZMnl5edn6fPHFF+rbt68aN24sFxcXdejQQZMnT86NUwIAAEAuc+oALEmtWrVSq1atbrndYrFozJgxGjNmzC37FC5cWHPnzs2O8gAAAJDHOPUcYAAAAMDRCMAAAAAwlbsKwMnJyVq5cqU+/vhjXbp0SZJ06tQpJSQkOLQ4AAAAwNGyPAf46NGjatasmY4dO6Zr166pSZMm8vPz09tvv61r165p+vTp2VEnAAAA4BBZvgL80ksvqWbNmrpw4YK8vb1t7e3bt7dbjxcAAABwRlm+Avzzzz9r/fr18vDwsGsvWbKkTp486bDCAAAAgOyQ5SvAqampSklJSdd+4sQJ+fn5OaQoAAAAILtkOQA3bdpUkyZNsj23WCxKSEjQyJEj1aJFC0fWBgAAADhclqdAvPfee4qKilLFihV19epVPfPMMzp48KCKFCmiefPmZUeNAAAAgMNkOQDff//92rlzpxYsWKCdO3cqISFB3bt3V3R0tN1NcQAAAIAzynIAXrt2rerUqaPo6GhFR0fb2pOTk7V27VrVr1/foQUCAAAAjpTlOcCNGjXS+fPn07VfvHhRjRo1ckhRAAAAQHbJcgA2DEMWiyVd+99//60CBQo4pCgAAAAgu2R6CsTjjz8uybrqQ9euXeXp6WnblpKSol27dqlOnTqOrxAAAABwoEwH4IIFC0qyXgH28/Ozu+HNw8NDtWvXVo8ePRxfIQAAAOBAmQ7As2bNkmT9xLdXXnmF6Q4AAADIk7K8CsTIkSOzow4AAAAgR2Q5AEvSV199pS+//FLHjh3T9evX7bZt27bNIYUBAAAA2SHLq0BMnjxZ3bp1U3BwsLZv365HHnlEgYGBOnTokJo3b54dNQIAAAAOk+UA/NFHH2nGjBmaMmWKPDw8NHjwYMXExKh///66ePFidtQIAAAAOEyWA/CxY8dsy515e3vr0qVLkqTnnntO8+bNc2x1AAAAgINlOQCHhITYPgnugQce0K+//ipJOnz4sAzDcGx1AAAAgINlOQA/9thj+u677yRJ3bp108CBA9WkSRM9/fTTat++vcMLBAAAABwpy6tAzJgxQ6mpqZKkPn36KDAwUOvXr1ebNm304osvOrxAAAAAwJGyHIBdXFzk4vLPheOOHTuqY8eODi0KAAAAyC53tQ5wXFycNm3apLNnz9quBqfp3LmzQwoDAAAAskOWA/D333+v6OhoJSQkyN/fXxaLxbbNYrEQgAEAAODUsnwT3Msvv6znn39eCQkJiouL04ULF2yPtNUhAAAAAGeV5QB88uRJ9e/fXz4+PtlRDwAAAJCtshyAo6KitGXLluyoBQAAAMh2WZ4D3LJlS7366qvau3evHnzwQbm7u9ttb9OmjcOKAwAAABwtywG4R48ekqQxY8ak22axWJSSknLvVQEAAADZJMsB+OZlzwAAAIC8JMtzgAEAAIC8LFNXgCdPnqyePXvKy8tLkydPvm3f/v37O6QwAAAAIDtkKgBPnDhR0dHR8vLy0sSJE2/Zz2KxEIABAADg1DIVgA8fPpzh9wAAAEBewxxgAAAAmEqmrgAPGjQo0wd8//3377oYAAAAILtlKgBv377d7vm2bduUnJyscuXKSZIOHDggV1dX1ahRw/EVAgAAAA6UqQC8Zs0a2/fvv/++/Pz8NGfOHBUqVEiSdOHCBXXr1k316tXLnioBAAAAB8nyHOD33ntP48aNs4VfSSpUqJDefPNNvffeew4tDgAAAHC0LAfg+Ph4/fXXX+na//rrL126dMkhRQEAAADZJcsBuH379urWrZsWLVqkEydO6MSJE/r666/VvXt3Pf7449lRIwAAAOAwmZoDfKPp06frlVde0TPPPKOkpCTrQdzc1L17d73zzjsOLxAAAABwpCwF4JSUFG3ZskVjx47VO++8oz///FOSVLp0aRUoUCBbCgQAAAAcKUsB2NXVVU2bNtW+ffsUFhamKlWqZFddAAAAQLbI8hzgypUr69ChQ9lRCwAAAJDtshyA33zzTb3yyitasmSJTp8+rfj4eLsHAAAA4MyyfBNcixYtJElt2rSRxWKxtRuGIYvFopSUFMdVBwAAADhYlgPwjZ8KBwAAAOQ1WQ7ADRo0yI46AAAAgByR5QAsSXFxcfrkk0+0b98+SVKlSpX0/PPPq2DBgg4tDgAAAHC0LN8Et2XLFpUuXVoTJ07U+fPndf78eb3//vsqXbq0tm3blh01AgAAAA6T5SvAAwcOVJs2bTRz5ky5uVl3T05O1gsvvKABAwZo7dq1Di8SAAAAcJQsB+AtW7bYhV/J+lHIgwcPVs2aNR1aHAAAAOBoWZ4C4e/vr2PHjqVrP378uPz8/BxSFAAAAJBdshyAn376aXXv3l0LFizQ8ePHdfz4cc2fP18vvPCCOnXqlB01AgAAAA6T5SkQ7777riwWizp37qzk5GRJkru7u3r16qXx48c7vEAAAADAkbIcgD08PPTBBx9o3Lhx+vPPPyVJpUuXlo+Pj8OLAwAAABztrtYBliQfHx8VKlTI9j0AAACQF2R5DnBqaqrGjBmjggULqkSJEipRooQCAgL0xhtvKDU1NTtqBAAAABwmy1eAhw0bpk8++UTjx49X3bp1JUm//PKLRo0apatXr2rs2LEOLxIAAABwlCwH4Dlz5ug///mP2rRpY2urUqWK7rvvPvXu3ZsADAAAAKeW5SkQ58+fV/ny5dO1ly9fXufPn3dIUQAAAEB2yXIAfuihhzR16tR07VOnTtVDDz3kkKIAAACA7JLlKRATJkxQy5YttXLlSkVEREiSNmzYoOPHj2vp0qUOLxAAAABwpCxfAW7QoIEOHDig9u3bKy4uTnFxcXr88ce1f/9+1atXLztqBAAAABzmrtYBDg0N5WY3AAAA5EmZvgJ88OBBderUSfHx8em2Xbx4Uc8884wOHTrk0OIAAAAAR8t0AH7nnXdUvHhx+fv7p9tWsGBBFS9eXO+8845DiwMAAAAcLdMB+KefftKTTz55y+1PPfWUVq9e7ZCiAAAAgOyS6QB87NgxFS1a9JbbixQpouPHjzukKAAAACC7ZDoAFyxYUH/++ectt//xxx8ZTo8AAAAAnEmmA3D9+vU1ZcqUW26fPHkyy6ABAADA6WU6AA8dOlT/+9//9MQTT2jTpk26ePGiLl68qI0bN6pDhw5avny5hg4dmp21AgAAAPcs0+sAV6tWTV999ZWef/55ffPNN3bbAgMD9eWXX6p69eoOLxAAAABwpCx9EEarVq109OhRLVu2TH/88YcMw1DZsmXVtGlT+fj4ZFeNAAAAgMNk+ZPgvL291b59++yoBQAAAMh2mZ4DDAAAAOQHBGAAAACYSqYD8KlTp7KzDgAAACBHZDoAV6pUSXPnzs3OWgAAAIBsl+kAPHbsWL344ot68skndf78+eysCQAAAMg2mQ7AvXv31q5du/T333+rYsWK+v7777OzLgAAACBbZGkZtLCwMK1evVpTp07V448/rgoVKsjNzf4Q27Ztc2iBAAAAgCNleRWIo0ePatGiRSpUqJDatm2b7gEAyH6jRo2SxWLRuXPnMtxeuXJlNWzYUJJ05MgRWSyWWz7Gjx8vSUpNTdXs2bPVpk0bFS9eXAUKFFDlypX15ptv6urVqzl1agCQ7bJ0BXjmzJl6+eWXFRkZqT179igoKCi76gIAOFinTp3UokWLdO3VqlWTJCUmJqpbt26qXbu2/vWvf6lo0aLasGGDRo4cqVWrVmn16tWyWCw5XTYAOFymA3CzZs20adMmTZ06VZ07d87OmgAA2aB69ep69tlnb7ndw8ND69atU506dWxtPXr0UMmSJW0hODIyMidKBYBslekpECkpKdq1axfhFwDyKQ8PD7vwm6Z9+/aSpH379uV0SQCQLTJ9BTgmJiY76wAAZLPExMQM5wwHBASku6H5RrGxsZKkIkWKZFttAJCT+ChkAHAyhiGdOycdOWL9ahiOOe7IkSMVFBSU7rFly5bb7jdhwgT5+/urefPmjikEAHJZngrA48ePl8Vi0YABA2xtV69eVZ8+fRQYGChfX1916NBBZ86csdvv2LFjatmypXx8fFS0aFG9+uqrSk5OzuHqAeD24uKkDz6QwsOloCApLMz6NTzc2h4Xd2/H79mzp2JiYtI9KlaseMt93nrrLa1cuVLjx49XQEDAvRUAIEdkdZWYdu3aycPD47arxEhS165dM+xTvnz5nDgth8rSKhC5afPmzfr4449VpUoVu/aBAwfqhx9+0MKFC1WwYEH17dtXjz/+uNatWyfJOne5ZcuWCgkJ0fr163X69Gl17txZ7u7ueuutt3LjVAAgneXLpQ4dpMTE9NsOHZIGDpSGDZO+/lqKisrcMW9esSE8PDxLN7EtWLBAr7/+urp3765evXplej8Aec/TTz+tVq1apWtPWyUmjaenp/7zn//YtRUsWDBba8sOeSIAJyQkKDo6WjNnztSbb75pa7948aI++eQTzZ07V4899pgkadasWapQoYJ+/fVX1a5dWytWrNDevXu1cuVKBQcHq2rVqnrjjTc0ZMgQjRo1Sh4eHrl1WgAgyRp+W7a0TnXIaLpDWtuVK9Z+P/wgeXl5/X/blQyPmZiYaOtzN2JiYtS5c2e1bNlS06dPv+vjAMgbqlWrdttVYtK4ubllqp+zyxMBuE+fPmrZsqUiIyPtAvDWrVuVlJRkd0WjfPnyeuCBB7RhwwbVrl1bGzZs0IMPPqjg4GBbn6ioKPXq1Ut79uxJ9382knTt2jVdu3bN9jw+Pl6SlJSUpKSkpOw4xRyVdg754VzyG8bGuWXH+Fy8KD37rOTlJaWm3rm/i4u1/9ix90mS9uzZo5CQELs+iYmJOn78uCIjI+1+b6WkpGSq9k2bNql9+/aqUaOGvvjiCxmG4fQ/k/zbcV6MTc5LSUmRdOvcYhiG7d912pTQzPx+SP3/X1JXr17V5cuX5e/v7+DK701WfsacPgDPnz9f27Zt0+bNm9Nti42NlYeHR7p5acHBwba7lmNjY+3Cb9r2tG0ZGTdunEaPHp2ufcWKFfLx8bmb03BKrOzhvBgb5+bo8bnpr4mZEheXKjc3N40ePVpXrlyRi8s/t3R89913Sk5OVpEiRbR06VLbfRG///67li5detvjHj9+XP/+978VGBioPn36aM2aNVkvLhfxb8d5MTY55+DBg5KklStXZhhSExISZLFY7H4/7N69W/Pnz0/Xt0CBAnJ1dZUknThxQomJiQoICNC1a9fk6+urevXqqXPnzvL29s7GM8qcxIzmkN2CUwfg48eP66WXXlJMTMw9/Skvq4YOHapBgwbZnsfHx6t48eJq2rSp0/3fzt1ISkpSTEyMmjRpInd399wuBzdgbJybo8fHMKRq1ayrPWRlpQeLRSpZUho+/KhGjhypd999V61atZKPj482bNigBQsWqEmTJho5cqRcXFx05MgRSdbpEhcuXEh3vNKlS6t27dq6dOmSqlatqsuXL+u1115TUlKSXf+0fs6IfzvOi7FxLMOQzp+XLl+WChSQChe2/k64UdrKLpGRkRkuX5j2P7ktWrTQH3/8IUmaN2+e5s2bl67vzz//rFq1akmS1q1bpxo1aqhatWpKTU3VihUr9Nlnn+nixYtauXLlbZdTzAlpf7HPDKcOwFu3btXZs2dVvXp1W1tKSorWrl2rqVOnavny5bp+/bri4uLsrgKfOXPG9ifBkJAQbdq0ye64af+3c/OfDdN4enrK09MzXbu7u3u++seb384nP2FsnJujxufcOWnv3rvbd+9eqU+fESpdurSmTp2qsWPHKjk5WWFhYRo9erSGDBli+z2WVuuCBQu0YMGCdMfq0qWL6tWrp/j4eB0/flySNGzYsFv2c2b823FejM29iYuT5syRpkyR/vzzn/bSpaV+/aQuXaS0KJR2xfZW73na6g3u7u620PrCCy/o6aefTte3SpUqtmNMmDDBbtuzzz6r8uXLa9iwYfr222/VsWPHez/Re5CVny+nDsCNGzfWb7/9ZtfWrVs3lS9fXkOGDFHx4sXl7u6uVatWqUOHDpKk/fv369ixY4qIiJAkRUREaOzYsTp79qyKFi0qyfpnGH9//9su/QMA2S0h4d72v3RJio6OVnR09G37lSxZUkYmLjFnth+AnJUTq8SUKVPmrj7qfODAgRo+fLhWrlyZ6wE4K5w6APv5+aly5cp2bQUKFFBgYKCtvXv37ho0aJAKFy4sf39/9evXTxEREbY/0zVt2lQVK1bUc889pwkTJig2Nlavv/66+vTpk+FVXgDIKb6+97a/n59j6gDgvJxxlZgbeXt7KzAwUOfPn3fI8XJKnvogjIxMnDhRrVq1UocOHVS/fn2FhIRo0aJFtu2urq5asmSJXF1dFRERoWeffVadO3fWmDFjcrFqAJACA61/vrx5/t6dWCzW/QoXzp66ADiHuDjrlV/DuPMqMamp1n4dOkhFipSQZP2r+M3SVokpUaKEQ2q8dOmSzp07p6CgIIccL6c49RXgjPz44492z728vPThhx/qww8/vOU+JUqUuOOdzwCQ0ywW69y9gQOzvm///lkPzgDyljlzrNMeMjszKTXV2v/Mmcby8PDQtGnT9Nhjj9mtEjNjxgwlJydn+aPNr169qqSkJPnd9KenN954Q4ZhqFmzZlk6Xm7LcwEYAPKTLl2sc/euXMn8OsDe3lLnztlfG4DcYxjWG97uxqxZRTV8+AgNH/666tevrzZt2sjHx0fr16/XvHnz1LRpU7Vu3dpun+3bt+vzzz9Pd6zSpUsrIiJCsbGxqlatmjp16mT76OPly5dr6dKlatasmdq2bXt3xeYSAjAA5KKAAOuNKy1bWsPt7UKwi4v1qu+iRf/c7Q0gf/r7b/vVHjLLMKz79eo1TGFhJTV16lSNGTMm3SoxN14Vlm6/SkxERIQCAgLUqlUrxcTEaM6cOUpJSVGZMmX01ltv6ZVXXkl3PGdHAAaAXBYVZb1x5ca7vG/8k2faVAdvb2v4bdo052sEkLNycpWYxYsXq0WLFrddRiwgIECfffbZvRXlRPJWXAeAfCoqSjpxQpo0SSpVyn5bqVLW9pMnCb+AWbBKTPbiCjAAOImAAOvNbf36WT/p6dIl63/EMvqkJwD5W9oqMYcOZf2TIkuVYpWYO+EKMAA4GYvF+h+/kiWtXwm/gPmkrRJzN1gl5s4IwAAAAE6oSxfJx8d6A2xmuLhY+7NKzJ0RgAEAAJxQ2ioxFsudQzCrxGQNARgAAMBJpa0S4+1tDbg3T21Ia/P2lpYu5UbZzCIAAwAAODFWiXE8VoEAAABwcqwS41gEYAAAgDwibZWYwMDcriRvYwoEAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFacOwOPGjdPDDz8sPz8/FS1aVO3atdP+/fvt+ly9elV9+vRRYGCgfH191aFDB505c8auz7Fjx9SyZUv5+PioaNGievXVV5WcnJyTpwIAAAAn4dQB+KefflKfPn3066+/KiYmRklJSWratKkuX75s6zNw4EB9//33WrhwoX766SedOnVKjz/+uG17SkqKWrZsqevXr2v9+vWaM2eOZs+erREjRuTGKQEAACCXueV2AbezbNkyu+ezZ89W0aJFtXXrVtWvX18XL17UJ598orlz5+qxxx6TJM2aNUsVKlTQr7/+qtq1a2vFihXau3evVq5cqeDgYFWtWlVvvPGGhgwZolGjRsnDwyM3Tg0AAAC5xKkD8M0uXrwoSSpcuLAkaevWrUpKSlJkZKStT/ny5fXAAw9ow4YNql27tjZs2KAHH3xQwcHBtj5RUVHq1auX9uzZo2rVqqV7nWvXrunatWu25/Hx8ZKkpKQkJSUlZcu55aS0c8gP55LfMDbOjfFxXoyN82JsnFt+Gp+snEOeCcCpqakaMGCA6tatq8qVK0uSYmNj5eHhoYCAALu+wcHBio2NtfW5MfymbU/blpFx48Zp9OjR6dpXrFghHx+fez0VpxETE5PbJeAWGBvnxvg4L8bGeTE2zi0/jE9iYmKm++aZANynTx/t3r1bv/zyS7a/1tChQzVo0CDb8/j4eBUvXlxNmzaVv79/tr9+dktKSlJMTIyaNGkid3f33C4HN2BsnBvj47wYG+fF2Di3/DQ+aX+xz4w8EYD79u2rJUuWaO3atbr//vtt7SEhIbp+/bri4uLsrgKfOXNGISEhtj6bNm2yO17aKhFpfW7m6ekpT0/PdO3u7u55/ofjRvntfPITxsa5MT7Oi7FxXoyNc8sP45OV+p16FQjDMNS3b1998803Wr16tcLCwuy216hRQ+7u7lq1apWtbf/+/Tp27JgiIiIkSREREfrtt9909uxZW5+YmBj5+/urYsWKOXMiAAAAcBpOfQW4T58+mjt3rr799lv5+fnZ5uwWLFhQ3t7eKliwoLp3765BgwapcOHC8vf3V79+/RQREaHatWtLkpo2baqKFSvqueee04QJExQbG6vXX39dffr0yfAqLwAAAPI3pw7A06ZNkyQ1bNjQrn3WrFnq2rWrJGnixIlycXFRhw4ddO3aNUVFRemjjz6y9XV1ddWSJUvUq1cvRUREqECBAurSpYvGjBmTU6cBAAAAJ+LUAdgwjDv28fLy0ocffqgPP/zwln1KlCihpUuXOrI0AAAA5FFOPQcYAAAAcDQCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCsBn98Yf9VwAAABMhAJvRwoXWr199lbt1AAAA5AICsBktWmT/FQAAwEQIwGazf7904ED67wEAAEyCAGw2X38tubpav3dxsT4HAAAwEQKw2SxYIKWmWr9PTbU+BwAAMBG33C4gJ3344Yd65513FBsbq4ceekhTpkzRI488kttlOdbVq9K2bZJhpN92/ry0a5fk7f1P286d0vffS4ULp+9vsUjVq0teXtlXLwAAQA4zTQBesGCBBg0apOnTp6tWrVqaNGmSoqKitH//fhUtWjS3y3OcmTOl/v1vvd3FJf3zNm1u3X/yZKlfP8fUBgAA4ARMMwXi/fffV48ePdStWzdVrFhR06dPl4+Pj/773//mdmmO1aOH1Lev9XuLJf32tOkPt3p+4379+lmPBwAAkI+Y4grw9evXtXXrVg0dOtTW5uLiosjISG3YsCFd/2vXrunatWu25/Hx8ZKkpKQkJSUlZX/B98LVVXr/fSkyUvrXv6TLl6XkZLsuSf8/BSLpxqkQadzcpAIFpI8/lpo3//8dnPyc85G0ny+n/zkzKcbHeTE2zouxcW75aXyycg4Ww8hosmj+curUKd13331av369IiIibO2DBw/WTz/9pI0bN9r1HzVqlEaPHp3uOHPnzpWPj0+21wsAAICsSUxM1DPPPKOLFy/K39//tn1NcQU4q4YOHapBgwbZnsfHx6t48eJq2rTpHd9Qp5OSIk2aJL3xhu3GuCRvb8X8979q8vzzcr9yxdrPYpGGD5cGDPhnmTTkuKSkJMXExKhJkyZyd3fP7XJwE8bHeTE2zouxcW75aXzS/mKfGaYIwEWKFJGrq6vOnDlj137mzBmFhISk6+/p6SlPT8907e7u7nnvh8PdXXr+eenf/063MoT7lSv2Abh7d1Z8cBJ58mfNRBgf58XYOC/Gxrnlh/HJSv2muAnOw8NDNWrU0KpVq2xtqampWrVqld2UiHxr8WLH9gMAAMjDTBGAJWnQoEGaOXOm5syZo3379qlXr166fPmyunXrltulZb+FC+1XhHBzs/8qWZdD+/LLnK0LAAAgF5hiCoQkPf300/rrr780YsQIxcbGqmrVqlq2bJmCg4Nzu7Tsdf68tGbNP8udubhI5cpZvw8Pl3bssG5LSbH2u3BBKlQo18oFAADIbqa5AixJffv21dGjR3Xt2jVt3LhRtWrVyu2Sst9331nD7Y1r+/74o/X7n37650MuLBZrv+++y5UyAQAAcoqpArApLVxo/RoQIC1ZYl0RwsPD2ubpaX3+/ffW7Tf2BwAAyKcIwPnd7t1Sw4bSnj1Sy5YZ92nVytqvQQPrVwAAgHzMNHOATWvPHusnu2X0scg3Cg21zgG+fDln6gIAAMglBOD8ztc3830tlqz1BwAAyIOYAgEAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEzFLbcLyAsMw5AkxcfH53IljpGUlKTExETFx8fL3d09t8vBDRgb58b4OC/GxnkxNs4tP41PWk5Ly223QwDOhEuXLkmSihcvnsuVAAAA4HYuXbqkggUL3raPxchMTDa51NRUnTp1Sn5+frJYLLldzj2Lj49X8eLFdfz4cfn7++d2ObgBY+PcGB/nxdg4L8bGueWn8TEMQ5cuXVJoaKhcXG4/y5crwJng4uKi+++/P7fLcDh/f/88/8OeXzE2zo3xcV6MjfNibJxbfhmfO135TcNNcAAAADAVAjAAAABMhQBsQp6enho5cqQ8PT1zuxTchLFxboyP82JsnBdj49zMOj7cBAcAAABT4QowAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQKwCX344YcqWbKkvLy8VKtWLW3atCm3S8rXxo0bp4cfflh+fn4qWrSo2rVrp/3799v1uXr1qvr06aPAwED5+vqqQ4cOOnPmjF2fY8eOqWXLlvLx8VHRokX16quvKjk5OSdPJd8bP368LBaLBgwYYGtjbHLXyZMn9eyzzyowMFDe3t568MEHtWXLFtt2wzA0YsQIFStWTN7e3oqMjNTBgwftjnH+/HlFR0fL399fAQEB6t69uxISEnL6VPKVlJQUDR8+XGFhYfL29lbp0qX1xhtv6Mb76hmbnLN27Vq1bt1aoaGhslgsWrx4sd12R43Frl27VK9ePXl5eal48eKaMGFCdp9a9jFgKvPnzzc8PDyM//73v8aePXuMHj16GAEBAcaZM2dyu7R8Kyoqypg1a5axe/duY8eOHUaLFi2MBx54wEhISLD1+de//mUUL17cWLVqlbFlyxajdu3aRp06dWzbk5OTjcqVKxuRkZHG9u3bjaVLlxpFihQxhg4dmhunlC9t2rTJKFmypFGlShXjpZdesrUzNrnn/PnzRokSJYyuXbsaGzduNA4dOmQsX77c+OOPP2x9xo8fbxQsWNBYvHixsXPnTqNNmzZGWFiYceXKFVufZs2aGQ899JDx66+/Gj///LNRpkwZo1OnTrlxSvnG2LFjjcDAQGPJkiXG4cOHjYULFxq+vr7GBx98YOvD2OScpUuXGsOGDTMWLVpkSDK++eYbu+2OGIuLFy8awcHBRnR0tLF7925j3rx5hre3t/Hxxx/n1Gk6FAHYZB555BGjT58+tucpKSlGaGioMW7cuFysylzOnj1rSDJ++uknwzAMIy4uznB3dzcWLlxo67Nv3z5DkrFhwwbDMKy/3FxcXIzY2Fhbn2nTphn+/v7GtWvXcvYE8qFLly4Z4eHhRkxMjNGgQQNbAGZscteQIUOMRx999JbbU1NTjZCQEOOdd96xtcXFxRmenp7GvHnzDMMwjL179xqSjM2bN9v6/O9//zMsFotx8uTJ7Cs+n2vZsqXx/PPP27U9/vjjRnR0tGEYjE1uujkAO2osPvroI6NQoUJ2v9eGDBlilCtXLpvPKHswBcJErl+/rq1btyoyMtLW5uLiosjISG3YsCEXKzOXixcvSpIKFy4sSdq6dauSkpLsxqV8+fJ64IEHbOOyYcMGPfjggwoODrb1iYqKUnx8vPbs2ZOD1edPffr0UcuWLe3GQGJsctt3332nmjVr6sknn1TRokVVrVo1zZw507b98OHDio2NtRufggULqlatWnbjExAQoJo1a9r6REZGysXFRRs3bsy5k8ln6tSpo1WrVunAgQOSpJ07d+qXX35R8+bNJTE2zsRRY7FhwwbVr19fHh4etj5RUVHav3+/Lly4kENn4zhuuV0Acs65c+eUkpJi9x9qSQoODtbvv/+eS1WZS2pqqgYMGKC6deuqcuXKkqTY2Fh5eHgoICDArm9wcLBiY2NtfTIat7RtuHvz58/Xtm3btHnz5nTbGJvcdejQIU2bNk2DBg3Sv//9b23evFn9+/eXh4eHunTpYnt/M3r/bxyfokWL2m13c3NT4cKFGZ978Nprryk+Pl7ly5eXq6urUlJSNHbsWEVHR0sSY+NEHDUWsbGxCgsLS3eMtG2FChXKlvqzCwEYyEF9+vTR7t279csvv+R2KZB0/PhxvfTSS4qJiZGXl1dul4ObpKamqmbNmnrrrbckSdWqVdPu3bs1ffp0denSJZerM7cvv/xSX3zxhebOnatKlSppx44dGjBggEJDQxkb5AlMgTCRIkWKyNXVNd0d7GfOnFFISEguVWUeffv21ZIlS7RmzRrdf//9tvaQkBBdv35dcXFxdv1vHJeQkJAMxy1tG+7O1q1bdfbsWVWvXl1ubm5yc3PTTz/9pMmTJ8vNzU3BwcGMTS4qVqyYKlasaNdWoUIFHTt2TNI/7+/tfqeFhITo7NmzdtuTk5N1/vx5xucevPrqq3rttdfUsWNHPfjgg3ruuec0cOBAjRs3ThJj40wcNRb57XcdAdhEPDw8VKNGDa1atcrWlpqaqlWrVikiIiIXK8vfDMNQ37599c0332j16tXp/oRUo0YNubu7243L/v37dezYMdu4RERE6LfffrP7BRUTEyN/f/90AQGZ17hxY/3222/asWOH7VGzZk1FR0fbvmdsck/dunXTLRl44MABlShRQpIUFhamkJAQu/GJj4/Xxo0b7cYnLi5OW7dutfVZvXq1UlNTVatWrRw4i/wpMTFRLi72EcLV1VWpqamSGBtn4qixiIiI0Nq1a5WUlGTrExMTo3LlyuW56Q+SWAbNbObPn294enoas2fPNvbu3Wv07NnTCAgIsLuDHY7Vq1cvo2DBgsaPP/5onD592vZITEy09fnXv/5lPPDAA8bq1auNLVu2GBEREUZERIRte9pSW02bNjV27NhhLFu2zAgKCmKprWxw4yoQhsHY5KZNmzYZbm5uxtixY42DBw8aX3zxheHj42N8/vnntj7jx483AgICjG+//dbYtWuX0bZt2wyXd6pWrZqxceNG45dffjHCw8NZausedenSxbjvvvtsy6AtWrTIKFKkiDF48GBbH8Ym51y6dMnYvn27sX37dkOS8f777xvbt283jh49ahiGY8YiLi7OCA4ONp577jlj9+7dxvz58w0fHx+WQUPeMWXKFOOBBx4wPDw8jEceecT49ddfc7ukfE1Sho9Zs2bZ+ly5csXo3bu3UahQIcPHx8do3769cfr0abvjHDlyxGjevLnh7e1tFClSxHj55ZeNpKSkHD6b/O/mAMzY5K7vv//eqFy5suHp6WmUL1/emDFjht321NRUY/jw4UZwcLDh6elpNG7c2Ni/f79dn7///tvo1KmT4evra/j7+xvdunUzLl26lJOnke/Ex8cbL730kvHAAw8YXl5eRqlSpYxhw4bZLZHF2OScNWvWZPjfmS5duhiG4bix2Llzp/Hoo48anp6exn333WeMHz8+p07R4SyGccPHtgAAAAD5HHOAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQDpdO3aVe3atbM9b9iwoQYMGJBr9QCAIxGAAcABUlJSVKdOHT3++ON27RcvXlTx4sU1bNiw2+7/xx9/qFu3brr//vvl6empsLAwderUSVu2bMnOsjNt0aJFeuONNxx6zFGjRqlq1aoOPSYAZAYBGAAcwNXVVbNnz9ayZcv0xRdf2Nr79eunwoULa+TIkbfcd8uWLapRo4YOHDigjz/+WHv37tU333yj8uXL6+WXX87WupOSkjLVr3DhwvLz88vWWgAgpxCAAcBBypYtq/Hjx6tfv346ffq0vv32W82fP1+ffvqpPDw8MtzHMAx17dpV4eHh+vnnn9WyZUuVLl1aVatW1ciRI/Xtt9/a+v7222967LHH5O3trcDAQPXs2VMJCQm27ampqRozZoztKnLVqlW1bNky2/YjR47IYrFowYIFatCggby8vPTFF18oJSVFgwYNUkBAgAIDAzV48GAZhmFX581TIEqWLKm33npLzz//vPz8/PTAAw9oxowZdvsMGTJEZcuWlY+Pj0qVKqXhw4fbAvfs2bM1evRo7dy5UxaLRRaLRbNnz5YkxcXF6YUXXlBQUJD8/f312GOPaefOnXc1JgCQEQIwADhQv3799NBDD+m5555Tz549NWLECD300EO37L9jxw7t2bNHL7/8slxc0v9KDggIkCRdvnxZUVFRKlSokDZv3qyFCxdq5cqV6tu3r63vBx98oPfee0/vvvuudu3apaioKLVp00YHDx60O+Zrr72ml156Sfv27VNUVJTee+89zZ49W//973/1yy+/6Pz58/rmm2/ueK7vvfeeatasqe3bt6t3797q1auX9u/fb9vu5+en2bNna+/evfrggw80c+ZMTZw4UZL09NNP6+WXX1alSpV0+vRpnT59Wk8//bQk6cknn9TZs2f1v//9T1u3blX16tXVuHFjnT9//o41AUCmGAAAh9q3b58hyXjwwQeNpKSk2/ZdsGCBIcnYtm3bbfvNmDHDKFSokJGQkGBr++GHHwwXFxcjNjbWMAzDCA0NNcaOHWu338MPP2z07t3bMAzDOHz4sCHJmDRpkl2fYsWKGRMmTLA9T0pKMu6//36jbdu2trYGDRoYL730ku15iRIljGeffdb2PDU11ShatKgxbdq0W57DO++8Y9SoUcP2fOTIkcZDDz1k1+fnn382/P39jatXr9q1ly5d2vj4449veWwAyAq3XM7fAJDv/Pe//5WPj48OHz6sEydOqGTJkrfsa9w01eBW9u3bp4ceekgFChSwtdWtW1epqanav3+/vL29derUKdWtW9duv7p166abPlCzZk3b9xcvXtTp06dVq1YtW5ubm5tq1qx5x9qqVKli+95isSgkJERnz561tS1YsECTJ0/Wn3/+qYSEBCUnJ8vf3/+2x9y5c6cSEhIUGBho137lyhX9+eeft90XADKLKRAA4EDr16/XxIkTtWTJEj3yyCPq3r37bYNk2bJlJUm///57TpVoF6Lvhbu7u91zi8Wi1NRUSdKGDRsUHR2tFi1aaMmSJdq+fbuGDRum69ev3/aYCQkJKlasmHbs2GH32L9/v1599VWH1A0ABGAAcJDExER17dpVvXr1UqNGjfTJJ59o06ZNmj59+i33qVq1qipWrKj33nvPFh5vFBcXJ0mqUKGCdu7cqcuXL9u2rVu3Ti4uLipXrpz8/f0VGhqqdevW2e2/bt06VaxY8ZavX7BgQRUrVkwbN260tSUnJ2vr1q2ZPe0MrV+/XiVKlNCwYcNUs2ZNhYeH6+jRo3Z9PDw8lJKSYtdWvXp1xcbGys3NTWXKlLF7FClS5J5qAoA0BGAAcJChQ4fKMAyNHz9eknWlhHfffVeDBw/WkSNHMtzHYrFo1qxZOnDggOrVq6elS5fq0KFD2rVrl8aOHau2bdtKkqKjo+Xl5aUuXbpo9+7dWrNmjfr166fnnntOwcHBkqRXX31Vb7/9thYsWKD9+/frtdde044dO/TSSy/dtu6XXnpJ48eP1+LFi/X777+rd+/etuB9t8LDw3Xs2DHNnz9ff/75pyZPnpzuxrqSJUvq8OHD2rFjh86dO6dr164pMjJSERERateunVasWKEjR45o/fr1GjZsmNOsiQwg7yMAA4AD/PTTT/rwww81a9Ys+fj42NpffPFF1alT57ZTIR555BFt2bJFZcqUUY8ePVShQgW1adNGe/bs0aRJkyRJPj4+Wr58uc6fP6+HH35YTzzxhBo3bqypU6fajtO/f38NGjRIL7/8sh588EEtW7ZM3333ncLDw29b+8svv6znnntOXbp0UUREhPz8/NS+fft7ej/atGmjgQMHqm/fvqpatarWr1+v4cOH2/Xp0KGDmjVrpkaNGikoKEjz5s2TxWLR0qVLVb9+fXXr1k1ly5ZVx44ddfToUVvQB4B7ZTEyewcGAAAAkA9wBRgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCr/B22aBa1HRdp+AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Approach 2: Use a DQN for resource allocation\n",
        "\n",
        "\n",
        "* Agent: The base station acts as the agent that allocates RBs to the UEs.\n",
        "* State: The state consists of the current conditions of the network, such as user channel gains, the RB allocation status, and the history of past allocations.\n",
        "* Action: The action is to assign a set of RBs to different UEs.\n",
        "* Reward: The reward is designed to reflect the performance of the network, including maximizing data rates and ensuring fairness across all UEs. The DQN learns to maximize cumulative rewards over time.\n",
        "* Objective: To train the DQN agent to learn an optimal resource allocation policy that adapts to network dynamics and achieves both high throughput and fairness.\n"
      ],
      "metadata": {
        "id": "BwU7o9vtc-jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "# Parameters\n",
        "NUM_UES = 5\n",
        "NUM_RBS = 200\n",
        "TRANSMISSION_POWER_DBM = 46\n",
        "NOISE_POWER_DBM = -90\n",
        "FREQUENCY_MHZ = 2000\n",
        "BASE_STATION_COORDS = (0, 0)\n",
        "AREA_SIZE = 1000\n",
        "\n",
        "# DQN Hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.99\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_END = 0.01\n",
        "EPSILON_DECAY = 0.995\n",
        "LEARNING_RATE = 0.001\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        np.random.seed(0)\n",
        "        self.ue_coords = np.random.uniform(0, AREA_SIZE, (NUM_UES, 2))\n",
        "        self.update_channel_gains()\n",
        "        self.current_allocation = np.zeros((NUM_UES, NUM_RBS), dtype=int)\n",
        "        return self._get_state()\n",
        "\n",
        "    def update_channel_gains(self):\n",
        "        distances = np.linalg.norm(self.ue_coords - np.array(BASE_STATION_COORDS), axis=1)\n",
        "        path_losses = np.array([self.cost_hata_path_loss(d / 1000) for d in distances])\n",
        "        snr_db = TRANSMISSION_POWER_DBM - path_losses - NOISE_POWER_DBM\n",
        "        snr_linear = 10 ** (snr_db / 10)\n",
        "        self.channel_gains = np.sqrt(snr_linear)\n",
        "\n",
        "    def cost_hata_path_loss(self, d_km):\n",
        "        A = 69.55 + 26.16 * np.log10(FREQUENCY_MHZ) - 13.82 * np.log10(30)\n",
        "        B = 44.9 - 6.55 * np.log10(30)\n",
        "        C = (1.1 * np.log10(FREQUENCY_MHZ) - 0.7) * 1.5 - (1.56 * np.log10(FREQUENCY_MHZ) - 0.8)\n",
        "        return A + B * np.log10(d_km) - C\n",
        "\n",
        "    def step(self, action):\n",
        "        ue, rb = action // NUM_RBS, action % NUM_RBS\n",
        "        self.current_allocation[ue, rb] = 1\n",
        "        reward = self._calculate_reward()\n",
        "        done = np.sum(self.current_allocation) == NUM_RBS\n",
        "        self._update_ue_positions()\n",
        "        return self._get_state(), reward, done\n",
        "\n",
        "    def _get_state(self):\n",
        "        return np.concatenate([self.current_allocation.flatten(), self.channel_gains])\n",
        "\n",
        "    def _calculate_reward(self):\n",
        "        data_rates = self._calculate_data_rates()\n",
        "        return np.sum(data_rates) + self._calculate_fairness(data_rates)\n",
        "\n",
        "    def _calculate_data_rates(self):\n",
        "        rb_bandwidth = 180e3\n",
        "        transmission_power = 10 ** ((TRANSMISSION_POWER_DBM - 30) / 10)\n",
        "        noise_power = 10 ** ((NOISE_POWER_DBM - 30) / 10)\n",
        "        data_rates = np.zeros(NUM_UES)\n",
        "        for u in range(NUM_UES):\n",
        "            allocated_rbs = np.sum(self.current_allocation[u])\n",
        "            if allocated_rbs > 0:\n",
        "                data_rates[u] = allocated_rbs * rb_bandwidth * np.log2(1 + (transmission_power * self.channel_gains[u]) / (noise_power * NUM_RBS * rb_bandwidth))\n",
        "        return data_rates\n",
        "\n",
        "    def _calculate_fairness(self, data_rates):\n",
        "        return (np.sum(data_rates) ** 2) / (NUM_UES * np.sum(data_rates ** 2))\n",
        "\n",
        "    def _update_ue_positions(self):\n",
        "        step_size = 1.0\n",
        "        self.ue_coords[0, 0] += step_size\n",
        "        self.ue_coords[0, 1] += step_size\n",
        "        self.ue_coords[1, 0] -= step_size\n",
        "        self.ue_coords[1, 1] -= step_size\n",
        "        self.update_channel_gains()\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, next_state, reward):\n",
        "        self.memory.append((state, action, next_state, reward))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "def select_action(state, policy_net, epsilon):\n",
        "    if random.random() > epsilon:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(NUM_UES * NUM_RBS)]], dtype=torch.long)\n",
        "\n",
        "def optimize_model(policy_net, target_net, optimizer, memory):\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    batch = list(zip(*transitions))\n",
        "\n",
        "    state_batch = torch.cat(batch[0])\n",
        "    action_batch = torch.cat(batch[1])\n",
        "    reward_batch = torch.cat(batch[3])\n",
        "\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch[2])), dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch[2] if s is not None])\n",
        "\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    next_state_values = torch.zeros(BATCH_SIZE)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def train_dqn(num_episodes):\n",
        "    env = Environment()\n",
        "    input_size = NUM_UES * NUM_RBS + NUM_UES\n",
        "    output_size = NUM_UES * NUM_RBS\n",
        "\n",
        "    policy_net = DQN(input_size, output_size)\n",
        "    target_net = DQN(input_size, output_size)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "    target_net.eval()\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "    epsilon = EPSILON_START\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "        total_reward = 0\n",
        "\n",
        "        while True:\n",
        "            action = select_action(state, policy_net, epsilon)\n",
        "            next_state, reward, done = env.step(action.item())\n",
        "            total_reward += reward\n",
        "\n",
        "            next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
        "            reward = torch.tensor([reward], dtype=torch.float32)\n",
        "\n",
        "            memory.push(state, action, next_state, reward)\n",
        "            state = next_state\n",
        "\n",
        "            optimize_model(policy_net, target_net, optimizer, memory)\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        epsilon = max(EPSILON_END, EPSILON_DECAY * epsilon)\n",
        "\n",
        "        if episode % TARGET_UPDATE == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "        print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
        "\n",
        "    return policy_net\n",
        "\n",
        "# Training\n",
        "trained_model = train_dqn(num_episodes=500)\n",
        "def perform_allocation(model, env):\n",
        "    model.eval()\n",
        "    state = env.reset()\n",
        "    allocation = np.zeros((NUM_UES, NUM_RBS), dtype=int)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(NUM_RBS):\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            action = model(state_tensor).max(1)[1].view(1, 1).item()\n",
        "\n",
        "            ue, rb = action // NUM_RBS, action % NUM_RBS\n",
        "\n",
        "            # Ensure we don't allocate the same RB twice\n",
        "            while allocation[ue, rb] == 1:\n",
        "                action = (action + 1) % (NUM_UES * NUM_RBS)\n",
        "                ue, rb = action // NUM_RBS, action % NUM_RBS\n",
        "\n",
        "            allocation[ue, rb] = 1\n",
        "            state, _, _ = env.step(action)\n",
        "\n",
        "    return allocation\n",
        "\n",
        "env = Environment()\n",
        "final_allocation = perform_allocation(trained_model, env)\n",
        "print(\"Final Resource Block Allocation:\")\n",
        "for ue in range(NUM_UES):\n",
        "    allocated_rbs = np.where(final_allocation[ue] == 1)[0]\n",
        "    print(f\"UE {ue + 1}: {allocated_rbs.tolist()}\")\n",
        "\n",
        "data_rates = env._calculate_data_rates()\n",
        "for ue in range(NUM_UES):\n",
        "    print(f\"UE {ue + 1} Data Rate: {data_rates[ue]:.2f} bps\")\n",
        "\n",
        "# Calculate and print the fairness index\n",
        "fairness = env._calculate_fairness(data_rates)\n",
        "print(f\"Fairness Index: {fairness:.4f}\")\n",
        "\n",
        "#total system throughput\n",
        "total_throughput = np.sum(data_rates)\n",
        "print(f\"Total System Throughput: {total_throughput:.2f} bps\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "12aiQE5hlktC",
        "outputId": "11104d98-f40a-41b5-e791-5d4fcf959232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1, Total Reward: 89607175223.16658\n",
            "Episode 2, Total Reward: 87634515555.40341\n",
            "Episode 3, Total Reward: 89249433610.1026\n",
            "Episode 4, Total Reward: 87260139699.39465\n",
            "Episode 5, Total Reward: 92910168733.84747\n",
            "Episode 6, Total Reward: 89559787584.69928\n",
            "Episode 7, Total Reward: 90648292256.54575\n",
            "Episode 8, Total Reward: 92166268556.80447\n",
            "Episode 9, Total Reward: 88093992648.89857\n",
            "Episode 10, Total Reward: 87805042081.19167\n",
            "Episode 11, Total Reward: 88210533786.06569\n",
            "Episode 12, Total Reward: 95254892151.24638\n",
            "Episode 13, Total Reward: 91149772034.0397\n",
            "Episode 14, Total Reward: 93164846117.72018\n",
            "Episode 15, Total Reward: 102192141128.84444\n",
            "Episode 16, Total Reward: 94748779948.46265\n",
            "Episode 17, Total Reward: 95872480282.67853\n",
            "Episode 18, Total Reward: 90238878278.91487\n",
            "Episode 19, Total Reward: 99676159724.0373\n",
            "Episode 20, Total Reward: 90095085921.31122\n",
            "Episode 21, Total Reward: 93266254578.56853\n",
            "Episode 22, Total Reward: 99396573540.54373\n",
            "Episode 23, Total Reward: 96072204116.68147\n",
            "Episode 24, Total Reward: 92464590282.00922\n",
            "Episode 25, Total Reward: 95347493074.67395\n",
            "Episode 26, Total Reward: 99420228527.85628\n",
            "Episode 27, Total Reward: 101822444880.66763\n",
            "Episode 28, Total Reward: 96680942139.56784\n",
            "Episode 29, Total Reward: 95708744881.78549\n",
            "Episode 30, Total Reward: 99036068237.33475\n",
            "Episode 31, Total Reward: 101816013909.01807\n",
            "Episode 32, Total Reward: 104967707902.41078\n",
            "Episode 33, Total Reward: 98857108079.39307\n",
            "Episode 34, Total Reward: 103883280917.34512\n",
            "Episode 35, Total Reward: 97790252140.0024\n",
            "Episode 36, Total Reward: 109226739990.93896\n",
            "Episode 37, Total Reward: 104540495945.89682\n",
            "Episode 38, Total Reward: 102657798502.43266\n",
            "Episode 39, Total Reward: 100818929425.19446\n",
            "Episode 40, Total Reward: 113697202966.9268\n",
            "Episode 41, Total Reward: 103336489695.82547\n",
            "Episode 42, Total Reward: 100808464813.42955\n",
            "Episode 43, Total Reward: 104066778512.01978\n",
            "Episode 44, Total Reward: 100152326151.61507\n",
            "Episode 45, Total Reward: 106018627238.32704\n",
            "Episode 46, Total Reward: 98424212507.71942\n",
            "Episode 47, Total Reward: 121083390502.72415\n",
            "Episode 48, Total Reward: 113995619110.43842\n",
            "Episode 49, Total Reward: 118491907000.81021\n",
            "Episode 50, Total Reward: 108314214518.33208\n",
            "Episode 51, Total Reward: 113019580034.97597\n",
            "Episode 52, Total Reward: 120507126456.06883\n",
            "Episode 53, Total Reward: 118738948392.8738\n",
            "Episode 54, Total Reward: 105722141433.84778\n",
            "Episode 55, Total Reward: 108023198379.49031\n",
            "Episode 56, Total Reward: 111505947021.51024\n",
            "Episode 57, Total Reward: 123831472473.21123\n",
            "Episode 58, Total Reward: 120788788584.38295\n",
            "Episode 59, Total Reward: 120554254687.31235\n",
            "Episode 60, Total Reward: 118273449645.25926\n",
            "Episode 61, Total Reward: 116057987455.27443\n",
            "Episode 62, Total Reward: 118833923489.02896\n",
            "Episode 63, Total Reward: 112072862278.3884\n",
            "Episode 64, Total Reward: 112904066026.49695\n",
            "Episode 65, Total Reward: 106817934207.1812\n",
            "Episode 66, Total Reward: 121793056700.48753\n",
            "Episode 67, Total Reward: 120770434449.58592\n",
            "Episode 68, Total Reward: 131052519377.45354\n",
            "Episode 69, Total Reward: 111840064660.82884\n",
            "Episode 70, Total Reward: 126002227619.0463\n",
            "Episode 71, Total Reward: 114465839471.74748\n",
            "Episode 72, Total Reward: 125326541451.67105\n",
            "Episode 73, Total Reward: 114322620465.64986\n",
            "Episode 74, Total Reward: 132839221294.998\n",
            "Episode 75, Total Reward: 133475251816.21793\n",
            "Episode 76, Total Reward: 123323792531.80057\n",
            "Episode 77, Total Reward: 131289799285.23973\n",
            "Episode 78, Total Reward: 143588379202.65265\n",
            "Episode 79, Total Reward: 105107002395.12383\n",
            "Episode 80, Total Reward: 113862308172.98682\n",
            "Episode 81, Total Reward: 135001672472.70546\n",
            "Episode 82, Total Reward: 127639347031.51216\n",
            "Episode 83, Total Reward: 129600822451.81393\n",
            "Episode 84, Total Reward: 133255962235.42592\n",
            "Episode 85, Total Reward: 127077310078.48268\n",
            "Episode 86, Total Reward: 125084484571.68593\n",
            "Episode 87, Total Reward: 121513465655.96338\n",
            "Episode 88, Total Reward: 123636138184.49846\n",
            "Episode 89, Total Reward: 117028429089.08723\n",
            "Episode 90, Total Reward: 129744723104.19899\n",
            "Episode 91, Total Reward: 127040206486.98877\n",
            "Episode 92, Total Reward: 138821733866.51453\n",
            "Episode 93, Total Reward: 137157550651.96632\n",
            "Episode 94, Total Reward: 126527617378.83759\n",
            "Episode 95, Total Reward: 125393161919.8142\n",
            "Episode 96, Total Reward: 122468870679.8669\n",
            "Episode 97, Total Reward: 129453855212.64046\n",
            "Episode 98, Total Reward: 125132100244.30182\n",
            "Episode 99, Total Reward: 122585571740.12352\n",
            "Episode 100, Total Reward: 133166330131.74063\n",
            "Episode 101, Total Reward: 145771625592.34235\n",
            "Episode 102, Total Reward: 135234376164.66649\n",
            "Episode 103, Total Reward: 131301987042.80255\n",
            "Episode 104, Total Reward: 129202752071.734\n",
            "Episode 105, Total Reward: 127668970772.68658\n",
            "Episode 106, Total Reward: 142292598409.1267\n",
            "Episode 107, Total Reward: 129518023897.3284\n",
            "Episode 108, Total Reward: 145653277607.2827\n",
            "Episode 109, Total Reward: 142540420813.856\n",
            "Episode 110, Total Reward: 119870204001.64413\n",
            "Episode 111, Total Reward: 147912936637.7204\n",
            "Episode 112, Total Reward: 143372215249.51593\n",
            "Episode 113, Total Reward: 140624001739.23392\n",
            "Episode 114, Total Reward: 131065350147.30757\n",
            "Episode 115, Total Reward: 147937028451.44543\n",
            "Episode 116, Total Reward: 152017176845.46707\n",
            "Episode 117, Total Reward: 136052295281.16139\n",
            "Episode 118, Total Reward: 135572807381.77275\n",
            "Episode 119, Total Reward: 139164134825.18985\n",
            "Episode 120, Total Reward: 133875472431.06993\n",
            "Episode 121, Total Reward: 144318383086.33328\n",
            "Episode 122, Total Reward: 135694087804.0533\n",
            "Episode 123, Total Reward: 145647700362.83755\n",
            "Episode 124, Total Reward: 150379164089.53235\n",
            "Episode 125, Total Reward: 149409057213.3956\n",
            "Episode 126, Total Reward: 131081867148.90082\n",
            "Episode 127, Total Reward: 170450849449.94315\n",
            "Episode 128, Total Reward: 154198211524.90152\n",
            "Episode 129, Total Reward: 155672824426.87515\n",
            "Episode 130, Total Reward: 145229936000.92978\n",
            "Episode 131, Total Reward: 146854392400.58624\n",
            "Episode 132, Total Reward: 162146076450.66837\n",
            "Episode 133, Total Reward: 152158839179.02756\n",
            "Episode 134, Total Reward: 172361903306.8386\n",
            "Episode 135, Total Reward: 153485154684.64972\n",
            "Episode 136, Total Reward: 168910473224.88052\n",
            "Episode 137, Total Reward: 153102837081.91782\n",
            "Episode 138, Total Reward: 169154664789.09363\n",
            "Episode 139, Total Reward: 163331453245.14084\n",
            "Episode 140, Total Reward: 153176351743.60825\n",
            "Episode 141, Total Reward: 165684147484.71103\n",
            "Episode 142, Total Reward: 157823068094.891\n",
            "Episode 143, Total Reward: 170700287307.61978\n",
            "Episode 144, Total Reward: 171990527751.9355\n",
            "Episode 145, Total Reward: 171224955580.64413\n",
            "Episode 146, Total Reward: 168858676642.87253\n",
            "Episode 147, Total Reward: 154929802926.82703\n",
            "Episode 148, Total Reward: 160952856067.09036\n",
            "Episode 149, Total Reward: 160657935785.3849\n",
            "Episode 150, Total Reward: 160064294357.85635\n",
            "Episode 151, Total Reward: 165412837155.36038\n",
            "Episode 152, Total Reward: 166021737291.62045\n",
            "Episode 153, Total Reward: 172206486503.0953\n",
            "Episode 154, Total Reward: 164244646690.7391\n",
            "Episode 155, Total Reward: 181794403148.34808\n",
            "Episode 156, Total Reward: 174179407856.5179\n",
            "Episode 157, Total Reward: 177415999126.47726\n",
            "Episode 158, Total Reward: 169164926802.57498\n",
            "Episode 159, Total Reward: 167200781017.82153\n",
            "Episode 160, Total Reward: 172089207690.6225\n",
            "Episode 161, Total Reward: 187145590307.97394\n",
            "Episode 162, Total Reward: 187836011105.85956\n",
            "Episode 163, Total Reward: 208295371046.97668\n",
            "Episode 164, Total Reward: 180100838042.13773\n",
            "Episode 165, Total Reward: 191319819588.3805\n",
            "Episode 166, Total Reward: 195402585379.86426\n",
            "Episode 167, Total Reward: 186210206303.19128\n",
            "Episode 168, Total Reward: 182657464223.04102\n",
            "Episode 169, Total Reward: 176613877344.39948\n",
            "Episode 170, Total Reward: 176471659262.47507\n",
            "Episode 171, Total Reward: 173142287707.43167\n",
            "Episode 172, Total Reward: 207855126587.03705\n",
            "Episode 173, Total Reward: 158829504787.51993\n",
            "Episode 174, Total Reward: 182801882484.766\n",
            "Episode 175, Total Reward: 201870915210.3667\n",
            "Episode 176, Total Reward: 202943730192.40225\n",
            "Episode 177, Total Reward: 187027407788.18848\n",
            "Episode 178, Total Reward: 190466739483.48544\n",
            "Episode 179, Total Reward: 189601062795.07703\n",
            "Episode 180, Total Reward: 187676687836.96103\n",
            "Episode 181, Total Reward: 195695903054.58713\n",
            "Episode 182, Total Reward: 209849689861.1619\n",
            "Episode 183, Total Reward: 196703324064.66205\n",
            "Episode 184, Total Reward: 194580686926.44574\n",
            "Episode 185, Total Reward: 198096941099.88757\n",
            "Episode 186, Total Reward: 184121562831.32535\n",
            "Episode 187, Total Reward: 212054255190.23737\n",
            "Episode 188, Total Reward: 223134273186.01813\n",
            "Episode 189, Total Reward: 188218950270.2441\n",
            "Episode 190, Total Reward: 187049347962.70486\n",
            "Episode 191, Total Reward: 214502415491.4015\n",
            "Episode 192, Total Reward: 212831944348.48212\n",
            "Episode 193, Total Reward: 210418624111.36676\n",
            "Episode 194, Total Reward: 205953472772.05963\n",
            "Episode 195, Total Reward: 208688137201.60236\n",
            "Episode 196, Total Reward: 207742321339.71317\n",
            "Episode 197, Total Reward: 219600521256.44656\n",
            "Episode 198, Total Reward: 214701577011.59167\n",
            "Episode 199, Total Reward: 222273220631.8098\n",
            "Episode 200, Total Reward: 224706725501.8822\n",
            "Episode 201, Total Reward: 214594824483.32297\n",
            "Episode 202, Total Reward: 233187906858.4682\n",
            "Episode 203, Total Reward: 215143267420.2145\n",
            "Episode 204, Total Reward: 239199827774.23956\n",
            "Episode 205, Total Reward: 224698842077.39697\n",
            "Episode 206, Total Reward: 216112167535.7809\n",
            "Episode 207, Total Reward: 206496835744.50977\n",
            "Episode 208, Total Reward: 226920086072.5858\n",
            "Episode 209, Total Reward: 212310240530.92413\n",
            "Episode 210, Total Reward: 247770866988.42084\n",
            "Episode 211, Total Reward: 221505418906.8198\n",
            "Episode 212, Total Reward: 221506929945.45285\n",
            "Episode 213, Total Reward: 265864496141.40714\n",
            "Episode 214, Total Reward: 227023151844.6921\n",
            "Episode 215, Total Reward: 221032134143.48788\n",
            "Episode 216, Total Reward: 255376125165.39093\n",
            "Episode 217, Total Reward: 236305354017.2986\n",
            "Episode 218, Total Reward: 264260441118.90082\n",
            "Episode 219, Total Reward: 221552780673.37683\n",
            "Episode 220, Total Reward: 227548998793.97232\n",
            "Episode 221, Total Reward: 216121616443.8154\n",
            "Episode 222, Total Reward: 216476659685.75806\n",
            "Episode 223, Total Reward: 223727794352.7202\n",
            "Episode 224, Total Reward: 237312842745.9524\n",
            "Episode 225, Total Reward: 251444602364.08517\n",
            "Episode 226, Total Reward: 240670949596.4721\n",
            "Episode 227, Total Reward: 240788709528.0886\n",
            "Episode 228, Total Reward: 219301363792.41623\n",
            "Episode 229, Total Reward: 237524956569.70923\n",
            "Episode 230, Total Reward: 256712173801.17587\n",
            "Episode 231, Total Reward: 249304078017.50385\n",
            "Episode 232, Total Reward: 260113126959.02417\n",
            "Episode 233, Total Reward: 246633093695.2368\n",
            "Episode 234, Total Reward: 256707813312.9395\n",
            "Episode 235, Total Reward: 258007845309.39053\n",
            "Episode 236, Total Reward: 256432335505.7423\n",
            "Episode 237, Total Reward: 247782512841.42484\n",
            "Episode 238, Total Reward: 263988744930.30264\n",
            "Episode 239, Total Reward: 245712490851.1133\n",
            "Episode 240, Total Reward: 232841103164.4781\n",
            "Episode 241, Total Reward: 256497964361.4401\n",
            "Episode 242, Total Reward: 256747247744.34412\n",
            "Episode 243, Total Reward: 281419282038.41504\n",
            "Episode 244, Total Reward: 266178138818.63168\n",
            "Episode 245, Total Reward: 252210305125.10498\n",
            "Episode 246, Total Reward: 255871819814.68512\n",
            "Episode 247, Total Reward: 312576503067.90234\n",
            "Episode 248, Total Reward: 225670785269.033\n",
            "Episode 249, Total Reward: 282833778655.0944\n",
            "Episode 250, Total Reward: 287017733300.87744\n",
            "Episode 251, Total Reward: 234096407895.56555\n",
            "Episode 252, Total Reward: 292998194284.20984\n",
            "Episode 253, Total Reward: 300084513488.5974\n",
            "Episode 254, Total Reward: 251554159639.56177\n",
            "Episode 255, Total Reward: 245435929300.7285\n",
            "Episode 256, Total Reward: 272441681559.64383\n",
            "Episode 257, Total Reward: 264659424776.08066\n",
            "Episode 258, Total Reward: 293470326289.58624\n",
            "Episode 259, Total Reward: 276135641029.1335\n",
            "Episode 260, Total Reward: 278618650626.35645\n",
            "Episode 261, Total Reward: 298312522407.7367\n",
            "Episode 262, Total Reward: 319671172349.94366\n",
            "Episode 263, Total Reward: 294137336756.6276\n",
            "Episode 264, Total Reward: 278921172430.91364\n",
            "Episode 265, Total Reward: 313914327298.61847\n",
            "Episode 266, Total Reward: 317991864204.68317\n",
            "Episode 267, Total Reward: 298005547297.667\n",
            "Episode 268, Total Reward: 282596901966.49384\n",
            "Episode 269, Total Reward: 285965019597.7314\n",
            "Episode 270, Total Reward: 299873356529.3262\n",
            "Episode 271, Total Reward: 294219205532.66205\n",
            "Episode 272, Total Reward: 280715787538.97565\n",
            "Episode 273, Total Reward: 295466901787.9627\n",
            "Episode 274, Total Reward: 314680537364.7496\n",
            "Episode 275, Total Reward: 289648994419.16833\n",
            "Episode 276, Total Reward: 357937294441.6804\n",
            "Episode 277, Total Reward: 332851829422.2586\n",
            "Episode 278, Total Reward: 292714466173.10205\n",
            "Episode 279, Total Reward: 286797279029.3471\n",
            "Episode 280, Total Reward: 283227647072.5147\n",
            "Episode 281, Total Reward: 331080201575.58575\n",
            "Episode 282, Total Reward: 310581076210.7058\n",
            "Episode 283, Total Reward: 309295991030.9799\n",
            "Episode 284, Total Reward: 326660529588.53766\n",
            "Episode 285, Total Reward: 310929922898.99506\n",
            "Episode 286, Total Reward: 341000580388.47363\n",
            "Episode 287, Total Reward: 379693361868.066\n",
            "Episode 288, Total Reward: 330457888684.08295\n",
            "Episode 289, Total Reward: 315329202527.39655\n",
            "Episode 290, Total Reward: 299007521629.7273\n",
            "Episode 291, Total Reward: 323255607732.3077\n",
            "Episode 292, Total Reward: 323328863766.8059\n",
            "Episode 293, Total Reward: 317165919876.7289\n",
            "Episode 294, Total Reward: 348325385675.3317\n",
            "Episode 295, Total Reward: 318600468564.0442\n",
            "Episode 296, Total Reward: 331616320216.37274\n",
            "Episode 297, Total Reward: 321166351238.2915\n",
            "Episode 298, Total Reward: 279185566445.96075\n",
            "Episode 299, Total Reward: 335640586806.6448\n",
            "Episode 300, Total Reward: 300720324222.128\n",
            "Episode 301, Total Reward: 338212428848.41113\n",
            "Episode 302, Total Reward: 356867029135.4104\n",
            "Episode 303, Total Reward: 351113350241.3078\n",
            "Episode 304, Total Reward: 308471124115.03705\n",
            "Episode 305, Total Reward: 366220907866.87244\n",
            "Episode 306, Total Reward: 324715817757.8713\n",
            "Episode 307, Total Reward: 355000818645.3124\n",
            "Episode 308, Total Reward: 343463324268.0094\n",
            "Episode 309, Total Reward: 357328399729.7447\n",
            "Episode 310, Total Reward: 310278996095.97974\n",
            "Episode 311, Total Reward: 401776070625.91205\n",
            "Episode 312, Total Reward: 374352086139.08417\n",
            "Episode 313, Total Reward: 321942323065.09717\n",
            "Episode 314, Total Reward: 364794634463.3431\n",
            "Episode 315, Total Reward: 348475310173.71405\n",
            "Episode 316, Total Reward: 309280348412.21436\n",
            "Episode 317, Total Reward: 409046624971.9523\n",
            "Episode 318, Total Reward: 348712215982.7505\n",
            "Episode 319, Total Reward: 379953177557.73376\n",
            "Episode 320, Total Reward: 344778092134.07263\n",
            "Episode 321, Total Reward: 306722371942.18274\n",
            "Episode 322, Total Reward: 340311672313.5876\n",
            "Episode 323, Total Reward: 349977266392.30725\n",
            "Episode 324, Total Reward: 347601377403.09125\n",
            "Episode 325, Total Reward: 367054828662.4223\n",
            "Episode 326, Total Reward: 372667837638.86237\n",
            "Episode 327, Total Reward: 355501165528.6394\n",
            "Episode 328, Total Reward: 382335064740.21533\n",
            "Episode 329, Total Reward: 347418357289.1123\n",
            "Episode 330, Total Reward: 354725187581.8389\n",
            "Episode 331, Total Reward: 439552418550.0073\n",
            "Episode 332, Total Reward: 405643022509.3762\n",
            "Episode 333, Total Reward: 397217354127.4654\n",
            "Episode 334, Total Reward: 362286999929.21265\n",
            "Episode 335, Total Reward: 377853374956.51447\n",
            "Episode 336, Total Reward: 397771881032.4341\n",
            "Episode 337, Total Reward: 437997487992.759\n",
            "Episode 338, Total Reward: 337352390209.58453\n",
            "Episode 339, Total Reward: 377727601508.44293\n",
            "Episode 340, Total Reward: 389135919335.72516\n",
            "Episode 341, Total Reward: 375361949384.99274\n",
            "Episode 342, Total Reward: 393742100276.37573\n",
            "Episode 343, Total Reward: 433783391699.26215\n",
            "Episode 344, Total Reward: 387743899055.9912\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-92e21d50b43a>\u001b[0m in \u001b[0;36m<cell line: 192>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperform_allocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-92e21d50b43a>\u001b[0m in \u001b[0;36mtrain_dqn\u001b[0;34m(num_episodes)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-92e21d50b43a>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(policy_net, target_net, optimizer, memory)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    224\u001b[0m             )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NwyAE_LXlFPM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}